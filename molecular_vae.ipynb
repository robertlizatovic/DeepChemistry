{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecular VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [10:37:38] Enabling RDKit 2019.09.1 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import torch.utils.data as tud\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# chemistry\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "IPythonConsole.ipython_useSVG=True  #set this to False if you want PNGs instead of SVGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChEMBL ID</th>\n",
       "      <th>Smiles</th>\n",
       "      <th>AlogP</th>\n",
       "      <th>QED Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL2333117</td>\n",
       "      <td>CC(C)Nc1c(C(N)=O)nnc2ccc(-c3cnn(C)c3)cc12</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL1189585</td>\n",
       "      <td>CC1C(=O)NC2=Nc3sc4c(c3CN21)CCCC4</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL4089494</td>\n",
       "      <td>CNC(=O)c1ccc(NC(=O)Nc2ccc(-c3nc(N4CCOCC4)c4ncc...</td>\n",
       "      <td>3.53</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL1189590</td>\n",
       "      <td>CN(C)c1nccc2c1nnn2Cc1ccccc1F</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL3927722</td>\n",
       "      <td>Cc1noc(C)c1Cn1cc(NC(=O)Cc2ccco2)cn1</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ChEMBL ID                                             Smiles  AlogP  \\\n",
       "0  CHEMBL2333117          CC(C)Nc1c(C(N)=O)nnc2ccc(-c3cnn(C)c3)cc12   1.95   \n",
       "1  CHEMBL1189585                   CC1C(=O)NC2=Nc3sc4c(c3CN21)CCCC4   1.95   \n",
       "2  CHEMBL4089494  CNC(=O)c1ccc(NC(=O)Nc2ccc(-c3nc(N4CCOCC4)c4ncc...   3.53   \n",
       "3  CHEMBL1189590                       CN(C)c1nccc2c1nnn2Cc1ccccc1F   2.08   \n",
       "4  CHEMBL3927722                Cc1noc(C)c1Cn1cc(NC(=O)Cc2ccco2)cn1   2.31   \n",
       "\n",
       "   QED Weighted  \n",
       "0          0.77  \n",
       "1          0.78  \n",
       "2          0.40  \n",
       "3          0.73  \n",
       "4          0.78  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chembl = pd.read_csv(\"data/cleaned_dataset.csv\")\n",
    "chembl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation & encoding\n",
    "\n",
    "Steps to prepare VAE input data:\n",
    "1. SMILES tokenization (add start/end tokens)\n",
    "2. SMILES token encoding (convert to integer indecies) -> build a vocabulary\n",
    "3. Set up a SMILES dataset class (for feeding batches of data to the VAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility classes/functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "code_folding": [
     0,
     29,
     140,
     184
    ]
   },
   "outputs": [],
   "source": [
    "class SMILESTokenizer(object):\n",
    "    \n",
    "    def __init__(self, pattern=\"(Br|Cl)\"):\n",
    "        self.pattern = re.compile(pattern)\n",
    "\n",
    "    def getPattern(self):\n",
    "        \"\"\"Returns compiled regex pattern for multi-character tokens\"\"\"\n",
    "        return self.pattern\n",
    "\n",
    "    def tokenize(self, smi:str) -> list:\n",
    "        \"\"\"Tokenizes an input SMILES string\"\"\"\n",
    "        if not self.pattern:\n",
    "            return list(smi)\n",
    "        # split input SMILES string using the supplied regex pattern    \n",
    "        splitted = self.pattern.split(smi)\n",
    "        tokens = []\n",
    "        for i, s in enumerate(splitted):\n",
    "            # make sure Br and Cl are treated as a single token\n",
    "            if i % 2 == 0:\n",
    "                tokens.extend(list(s))\n",
    "            else:\n",
    "                tokens.append(s)\n",
    "        return tokens\n",
    "\n",
    "    def untokenize(self, tokens:list) -> str:\n",
    "        \"\"\"Concatenates a list of tokens into a SMILES string\"\"\"\n",
    "        return \"\".join(tokens)\n",
    "    \n",
    "\n",
    "class SMILESVocabulary(object):\n",
    "    \"\"\"Keeps track of string tokens and their associated integer indecies\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._tokens_idxs = {} # vocabulary\n",
    "        self._current_idx = 0 # currently available index\n",
    "        # add start, end, padding tokens\n",
    "        self.sos = \"<sos>\"\n",
    "        self.eos = \"<eos>\"\n",
    "        self.pad = \"<pad>\"\n",
    "        self.update([self.pad, self.sos, self.eos])\n",
    "            \n",
    "    def __getitem__(self, token_or_idx):\n",
    "        return self._tokens_idxs[token_or_idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._tokens_idxs) // 2\n",
    "    \n",
    "    def getStartIdx(self):\n",
    "        return self._tokens_idxs[self.sos]\n",
    "    \n",
    "    def getEndIdx(self):\n",
    "        return self._tokens_idxs[self.eos]\n",
    "    \n",
    "    def getPadIdx(self):\n",
    "        return self._tokens_idxs[self.pad]\n",
    "    \n",
    "    def add(self, token:str):\n",
    "        assert type(token) == str, \"Token must be of type string.\"\n",
    "        if token not in self._tokens_idxs:\n",
    "            self._tokens_idxs[token] = self._current_idx\n",
    "            self._tokens_idxs[self._current_idx] = token\n",
    "            # update first available index\n",
    "            self._current_idx += 1\n",
    "            \n",
    "    def tokens(self):\n",
    "        \"\"\"Returns a list of all tokens in the vocabulary\"\"\"\n",
    "        return [t for t in self._tokens_idxs if type(t) == str]\n",
    "\n",
    "    def update(self, tokens:list):\n",
    "        \"\"\"Updates the vocabulary with an iterable of tokens\"\"\"\n",
    "        for t in tokens:\n",
    "            self.add(t)\n",
    "        \n",
    "    def encode(self, tokens:list) -> list:\n",
    "        \"\"\"\n",
    "        Encodes a list of tokens as a list of integer indecies.\n",
    "        Attaches sos and eos idecies at the beginning and end of\n",
    "        the encoded sequence.\n",
    "        \"\"\"\n",
    "        smi_seq = [self._tokens_idxs[t] for t in tokens]\n",
    "        return [self.getStartIdx()] + smi_seq + [self.getEndIdx()]\n",
    "    \n",
    "    def decode(self, indices:list) -> list:\n",
    "        \"\"\"\n",
    "        Decodes a list of interger indices as a list of tokens.\n",
    "        Ignores 1st sos idx and truncates the sequence if it encounters\n",
    "        a special idx further down. \n",
    "        \"\"\"\n",
    "        tokens = []\n",
    "        spec_idxs = [self.getStartIdx(), self.getEndIdx(), self.getPadIdx()]\n",
    "        for i, idx in enumerate(indices):\n",
    "            if (idx == self.getStartIdx()) & (i == 0):\n",
    "                continue\n",
    "            if (idx in spec_idxs) & (i > 0):\n",
    "                break\n",
    "            else:\n",
    "                tokens.append(self._tokens_idxs[idx])\n",
    "        return tokens\n",
    "\n",
    "    def build(self, smiles:list, tokenizer:SMILESTokenizer) -> None:\n",
    "        \"\"\"\n",
    "        Builds a vocabulary using a list of SMILES and\n",
    "        an instance of a Tokenizer object. Any existing\n",
    "        vocabulary is reset.\n",
    "        -------------------------------\n",
    "        smiles - iterable of SMILES strings\n",
    "        tokenizer - instantiated SMILESTokenizer object\n",
    "        \n",
    "        returns None\n",
    "        \"\"\"\n",
    "        # reset current vocabulary\n",
    "        self.__init__()\n",
    "        # build new vocabulary\n",
    "        tokens = set()\n",
    "        for smi in smiles:\n",
    "            tokens.update(tokenizer.tokenize(smi))\n",
    "        self.update(sorted(tokens))\n",
    "        \n",
    "    def save(self, path):\n",
    "        \"\"\"Saves the vocabulary to disk\"\"\"\n",
    "        voc = [[k, v] for k, v in self._tokens_idxs.items() if isinstance(k, str)]\n",
    "        voc_df = pd.DataFrame(voc, columns=[\"token\", \"index\"])\n",
    "        voc_df.to_csv(path, index=False)\n",
    "    \n",
    "    def load(self, path):\n",
    "        \"\"\"Loads a stored vocabulary from disk\"\"\"\n",
    "        # reset current vocabulary\n",
    "        self.__init__()\n",
    "        # build vocabulary from csv file\n",
    "        voc_df = pd.read_csv(path)\n",
    "        for _, row in voc_df.iterrows():\n",
    "            token = row[\"token\"]\n",
    "            idx = row[\"index\"]\n",
    "            self._tokens_idxs[token] = idx\n",
    "            self._tokens_idxs[idx] = token\n",
    "            self._current_idx = max(self._current_idx, idx)\n",
    "        # update the currently available index\n",
    "        self._current_idx += 1\n",
    "\n",
    "\n",
    "class SMILESDataset(tud.Dataset):\n",
    "    \"\"\"Custom dataset class for producing batches of SMILES\"\"\"\n",
    "    \n",
    "    def __init__(self, smiles, vocabulary:SMILESVocabulary, tokenizer:SMILESTokenizer):\n",
    "        \"\"\"\n",
    "        Creates a dataset from an iterable of SMILES, a built vocabulary of tokens\n",
    "        and a SMILES tokenizer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self._smiles = list(smiles)\n",
    "        self._vocabulary = vocabulary\n",
    "        self._tokenizer = tokenizer\n",
    "        \n",
    "    def __getitem__(self, idx:int):\n",
    "        \"\"\"Returns a molecule at index idx as an encoded SMILES tensor\"\"\"\n",
    "        smi = self._smiles[idx]\n",
    "        smi_enc = self._vocabulary.encode(self._tokenizer.tokenize(smi))\n",
    "        return torch.LongTensor(smi_enc)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._smiles)\n",
    "    \n",
    "    def getCollateFn(self):\n",
    "        \"\"\"\n",
    "        Generates the collate function that will pad all\n",
    "        sequences in a batch to the same max. length using the pad idx\n",
    "        defined in the vocabulary.\n",
    "        \"\"\"\n",
    "        def collate_fn(enc_tensors:list):\n",
    "            \"\"\"\n",
    "            Pads encoded SMILES tensors to the same max. length using the pad idx.\n",
    "            The output tensor has shape: (batch_sz, max. length)\n",
    "            \"\"\"\n",
    "            batch_sz = len(enc_tensors)\n",
    "            max_len = max([t.size(0) for t in enc_tensors])\n",
    "            padded = torch.full((batch_sz, max_len), self._vocabulary.getPadIdx(), dtype=torch.long)\n",
    "            # pad encoded batch of SMILES\n",
    "            for i, t in enumerate(enc_tensors):\n",
    "                padded[i, :t.size(0)] = t\n",
    "            return padded\n",
    "        \n",
    "        return collate_fn\n",
    "\n",
    "\n",
    "def countTokens(smiles:list, tokenizer:SMILESTokenizer, tokenCol:str=\"token\", cntCol:str=\"cnt\") -> pd.DataFrame:\n",
    "    \"\"\"Computes the token frequency in the smiles iterable\"\"\"\n",
    "    token_cnts = {}\n",
    "    for smi in smiles:\n",
    "        # tokenize SMILES string\n",
    "        tokenized = tokenizer.tokenize(smi)\n",
    "        # count tokens\n",
    "        for t in tokenized:\n",
    "            try:\n",
    "                token_cnts[t] += 1\n",
    "            except KeyError:\n",
    "                token_cnts[t] = 1\n",
    "    return pd.DataFrame([[t, c] for t, c in token_cnts.items()], columns=[tokenCol, cntCol])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SMILESTokenizer()\n",
    "vocabulary = SMILESVocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary.build(chembl[\"Smiles\"], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save vocabulary\n",
    "# vocabulary.save(\"data/vocabulary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vocabulary\n",
    "vocabulary.load(\"data/vocabulary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze token frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>12896279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(</td>\n",
       "      <td>7025189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>)</td>\n",
       "      <td>7025189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>2682981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c</td>\n",
       "      <td>18431345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>4604265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>=</td>\n",
       "      <td>2904352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>O</td>\n",
       "      <td>4388805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n</td>\n",
       "      <td>2124346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>3590237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>576826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>1781615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>s</td>\n",
       "      <td>190809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>530543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>F</td>\n",
       "      <td>577815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>o</td>\n",
       "      <td>190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cl</td>\n",
       "      <td>340814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[</td>\n",
       "      <td>1253085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@</td>\n",
       "      <td>1286887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>H</td>\n",
       "      <td>936158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>]</td>\n",
       "      <td>1253085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S</td>\n",
       "      <td>418728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>98750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>#</td>\n",
       "      <td>109078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Br</td>\n",
       "      <td>70038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>/</td>\n",
       "      <td>345947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\\</td>\n",
       "      <td>78135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6</td>\n",
       "      <td>11356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7</td>\n",
       "      <td>1131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>P</td>\n",
       "      <td>20234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>p</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>+</td>\n",
       "      <td>102796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>I</td>\n",
       "      <td>9080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>%</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token       cnt\n",
       "0      C  12896279\n",
       "1      (   7025189\n",
       "2      )   7025189\n",
       "3      N   2682981\n",
       "4      c  18431345\n",
       "5      1   4604265\n",
       "6      =   2904352\n",
       "7      O   4388805\n",
       "8      n   2124346\n",
       "9      2   3590237\n",
       "10     -    576826\n",
       "11     3   1781615\n",
       "12     s    190809\n",
       "13     4    530543\n",
       "14     F    577815\n",
       "15     o    190476\n",
       "16    Cl    340814\n",
       "17     [   1253085\n",
       "18     @   1286887\n",
       "19     H    936158\n",
       "20     ]   1253085\n",
       "21     S    418728\n",
       "22     5     98750\n",
       "23     #    109078\n",
       "24    Br     70038\n",
       "25     /    345947\n",
       "26     \\     78135\n",
       "27     6     11356\n",
       "28     8       516\n",
       "29     7      1131\n",
       "30     P     20234\n",
       "31     p        17\n",
       "32     +    102796\n",
       "33     I      9080\n",
       "34     9        17\n",
       "35     %         8\n",
       "36     0         4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_cnts = countTokens(chembl[\"Smiles\"], tokenizer)\n",
    "token_cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAF+CAYAAADHg73fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dfbhmdV3v8ffHAQwVpZzRkAcHPeRjgjiBiCmYD1Aa2dFiMtOU5tARj1nZoboOdOxYx8Px1ElQ4igRJVCiKFeNgmmJ+ZAMyMMgoIQY05gMIuJT4uD3/LHW1pvtnpl175m194+936/ruq9932ut71q/vff98Ll/67fWSlUhSZKkNtxvsRsgSZKk7zGcSZIkNcRwJkmS1BDDmSRJUkMMZ5IkSQ0xnEmSJDVkyYWzJGcnuS3JxgHL/lGSq/rbZ5LcuRBtlCRJ2pYstfOcJXkG8DXg3Kp64hR1rwaeXFWvGK1xkiRJO7Dkes6q6jLgjslpSR6d5P1JrkjykSSPnaN0LXD+gjRSkiRpG3Zb7AYskLOAE6vqs0kOB94CPGtmZpJHAgcCH1qk9kmSJAHLIJwleRDwNOCdSWYm33/WYscDF1bVPQvZNkmSpNmWfDij23V7Z1Udsp1ljgdetUDtkSRJ2qYlN+Zstqq6C/hckhcDpHPwzPwkjwF+EPj4IjVRkiTpu5ZcOEtyPl3QekySTUleCbwEeGWSq4HrgOMmStYCF9RSO2xVkiTdJy25U2lIkiTdly25njNJkqT7MsOZJElSQ5bU0ZorV66s1atXL3YzJEmSduiKK664vapWzZ6+pMLZ6tWr2bBhw2I3Q5IkaYeSfH6u6e7WlCRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJashui92AXe3Frz9/quXfecrakVoiSZI0PXvOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIaNdWzPJ2cDzgduq6olzzH8d8JKJdjwOWFVVdyS5BfgqcA+wtarWjNVOSZKklozZc3YOcMy2ZlbVaVV1SFUdAvw28OGqumNikaP7+QYzSZK0bIwWzqrqMuCOHS7YWQucP1ZbJEmS7isWfcxZkgfQ9bC9a2JyAZcmuSLJusVpmSRJ0sIbbczZFF4AfHTWLs0jq2pzkocBH0hyQ98T93368LYO4IADDuDA8dsrSZI0mkXvOQOOZ9Yuzara3P+8DbgIOGxbxVV1VlWtqao1q1atGrWhkiRJY1vUcJbkIcAzgfdOTHtgkr1m7gPPBTYuTgslSZIW1pin0jgfOApYmWQTcCqwO0BVndkv9kLg0qr6+kTpw4GLksy077yqev9Y7ZQkSWrJaOGsqtYOWOYculNuTE67GTh4nFZJkiS1rYUxZ5IkSeoZziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGjJaOEtydpLbkmzcxvyjknwlyVX97ZSJecckuTHJTUlOHquNkiRJrRmz5+wc4JgdLPORqjqkv70eIMkK4AzgWODxwNokjx+xnZIkSc0YLZxV1WXAHfMoPQy4qapurqq7gQuA43Zp4yRJkhq12GPOjkhydZL3JXlCP21f4NaJZTb10+aUZF2SDUk2bNmyZcy2SpIkjW4xw9mVwCOr6mDgzcB7+umZY9na1kqq6qyqWlNVa1atWjVCMyVJkhbOooWzqrqrqr7W318P7J5kJV1P2f4Ti+4HbF6EJkqSJC24RQtnSX44Sfr7h/Vt+RJwOXBQkgOT7AEcD1y8WO2UJElaSLuNteIk5wNHASuTbAJOBXYHqKozgRcBv5pkK/BN4PiqKmBrkpOAS4AVwNlVdd1Y7ZQkSWrJaOGsqtbuYP7pwOnbmLceWD9GuyRJklq22EdrSpIkaYLhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWrIbovdgJa8+PXnT7X8O09ZO1JLJEnScmXPmSRJUkMMZ5IkSQ0xnEmSJDVktHCW5OwktyXZuI35L0lyTX/7WJKDJ+bdkuTaJFcl2TBWGyVJklozZs/ZOcAx25n/OeCZVfUk4PeBs2bNP7qqDqmqNSO1T5IkqTmjHa1ZVZclWb2d+R+bePgJYL+x2iJJknRf0cqYs1cC75t4XMClSa5Ism57hUnWJdmQZMOWLVtGbaQkSdLYFv08Z0mOpgtnT5+YfGRVbU7yMOADSW6oqsvmqq+qs+h3ia5Zs6ZGb7AkSdKIFrXnLMmTgLcBx1XVl2amV9Xm/udtwEXAYYvTQkmSpIW1aOEsyQHAu4GXVtVnJqY/MMleM/eB5wJzHvEpSZK01Iy2WzPJ+cBRwMokm4BTgd0BqupM4BTgocBbkgBs7Y/MfDhwUT9tN+C8qnr/WO2UJElqyZhHa273wpNVdQJwwhzTbwYO/v4KSZKkpa+VozUlSZKE4UySJKkphjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJasho4SzJ2UluS7JxG/OT5E+S3JTkmiSHTsw7JsmN/byTx2qjJElSa8bsOTsHOGY7848FDupv64C3AiRZAZzRz388sDbJ40dspyRJUjNGC2dVdRlwx3YWOQ44tzqfAPZOsg9wGHBTVd1cVXcDF/TLSpIkLXmDwlmS1wyZNqV9gVsnHm/qp21r+rbati7JhiQbtmzZspNNkiRJWlxDe85eNse0l+/ktjPHtNrO9DlV1VlVtaaq1qxatWonmyRJkrS4dtvezCRrgV8ADkxy8cSsvYAv7eS2NwH7TzzeD9gM7LGN6ZIkSUvedsMZ8DHgC8BK4E0T078KXLOT274YOCnJBcDhwFeq6gtJtgAHJTkQ+FfgeLqAKEmStORtN5xV1eeBzwNHTLviJOcDRwErk2wCTgV279d7JrAe+EngJuAbwC/387YmOQm4BFgBnF1V1027fUmSpPuiHfWcAZDkZ4E3Ag+jGxMWoKrqwduqqaq121tnVRXwqm3MW08X3iRJkpaVQeEM+F/AC6rq+jEbI0mStNwNPVrziwYzSZKk8Q3tOduQ5K+A9wDfmplYVe8epVWSJEnL1NBw9mC6QfvPnZhWgOFMkiRpFxoazu4HvKaq7gRI8oPc+9QakiRJ2gWGjjl70kwwA6iqLwNPHqdJkiRJy9fQcHa/vrcMgCQ/xPBeN0mSJA00NGC9CfhYkgvpxpr9HPCG0VolSZK0TA0KZ1V1bpINwLPoTkD7s1X16VFbJkmStAwN3jXZhzEDmSRJ0oiGjjmTJEnSAjCcSZIkNcRwJkmS1BDDmSRJUkMMZ5IkSQ0xnEmSJDXEcCZJktQQw5kkSVJDDGeSJEkNMZxJkiQ1xHAmSZLUEMOZJElSQwxnkiRJDTGcSZIkNcRwJkmS1BDDmSRJUkMMZ5IkSQ0xnEmSJDXEcCZJktQQw5kkSVJDDGeSJEkNMZxJkiQ1xHAmSZLUkFHDWZJjktyY5KYkJ88x/3VJrupvG5Pck+SH+nm3JLm2n7dhzHZKkiS1YrexVpxkBXAG8BxgE3B5kour6tMzy1TVacBp/fIvAF5bVXdMrOboqrp9rDZKkiS1Zsyes8OAm6rq5qq6G7gAOG47y68Fzh+xPZIkSc0bM5ztC9w68XhTP+37JHkAcAzwronJBVya5Iok67a1kSTrkmxIsmHLli27oNmSJEmLZ8xwljmm1TaWfQHw0Vm7NI+sqkOBY4FXJXnGXIVVdVZVramqNatWrdq5FkuSJC2yMcPZJmD/icf7AZu3sezxzNqlWVWb+5+3ARfR7SaVJEla0sYMZ5cDByU5MMkedAHs4tkLJXkI8EzgvRPTHphkr5n7wHOBjSO2VZIkqQmjHa1ZVVuTnARcAqwAzq6q65Kc2M8/s1/0hcClVfX1ifKHAxclmWnjeVX1/rHaKkmS1IrRwhlAVa0H1s+aduasx+cA58yadjNw8JhtkyRJapFXCJAkSWqI4UySJKkho+7WXE5e/Prpzp/7zlPW7pJaSZK0tNhzJkmS1BDDmSRJUkMMZ5IkSQ0xnEmSJDXEcCZJktQQw5kkSVJDDGeSJEkNMZxJkiQ1xHAmSZLUEMOZJElSQwxnkiRJDTGcSZIkNcRwJkmS1BDDmSRJUkMMZ5IkSQ0xnEmSJDXEcCZJktQQw5kkSVJDDGeSJEkNMZxJkiQ1xHAmSZLUEMOZJElSQwxnkiRJDTGcSZIkNcRwJkmS1BDDmSRJUkMMZ5IkSQ0xnEmSJDXEcCZJktQQw5kkSVJDRg1nSY5JcmOSm5KcPMf8o5J8JclV/e2UobWSJElL0W5jrTjJCuAM4DnAJuDyJBdX1adnLfqRqnr+PGslSZKWlDF7zg4Dbqqqm6vqbuAC4LgFqJUkSbrPGjOc7QvcOvF4Uz9ttiOSXJ3kfUmeMGWtJEnSkjJmOMsc02rW4yuBR1bVwcCbgfdMUdstmKxLsiHJhi1btsy7sZIkSS0YM5xtAvafeLwfsHlygaq6q6q+1t9fD+yeZOWQ2ol1nFVVa6pqzapVq3Zl+yVJkhbcmOHscuCgJAcm2QM4Hrh4coEkP5wk/f3D+vZ8aUitJEnSUjTa0ZpVtTXJScAlwArg7Kq6LsmJ/fwzgRcBv5pkK/BN4PiqKmDO2rHaKkmS1IrRwhl8d1fl+lnTzpy4fzpw+tBaSZKkpc4rBEiSJDVk1J4zje/Frz9/quXfecrakVoiSZJ2BXvOJEmSGmI4kyRJaojhTJIkqSGOOVvGph2vBo5ZkyRpbPacSZIkNcRwJkmS1BDDmSRJUkMMZ5IkSQ0xnEmSJDXEcCZJktQQw5kkSVJDDGeSJEkNMZxJkiQ1xHAmSZLUEMOZJElSQwxnkiRJDfHC55q3aS+c7kXTJUnaMXvOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIV5bU4vC63JKkjQ3e84kSZIaYjiTJElqyKjhLMkxSW5MclOSk+eY/5Ik1/S3jyU5eGLeLUmuTXJVkg1jtlOSJKkVo405S7ICOAN4DrAJuDzJxVX16YnFPgc8s6q+nORY4Czg8In5R1fV7WO1UfdNjleTJC1lY/acHQbcVFU3V9XdwAXAcZMLVNXHqurL/cNPAPuN2B5JkqTmjRnO9gVunXi8qZ+2La8E3jfxuIBLk1yRZN0I7ZMkSWrOmKfSyBzTas4Fk6PpwtnTJyYfWVWbkzwM+ECSG6rqsjlq1wHrAA444AAO3Pl2S5IkLZoxe842AftPPN4P2Dx7oSRPAt4GHFdVX5qZXlWb+5+3ARfR7Sb9PlV1VlWtqao1q1at2oXNlyRJWnhjhrPLgYOSHJhkD+B44OLJBZIcALwbeGlVfWZi+gOT7DVzH3gusHHEtkqSJDVhtN2aVbU1yUnAJcAK4Oyqui7Jif38M4FTgIcCb0kCsLWq1gAPBy7qp+0GnFdV7x+rrZIkSa0Y9fJNVbUeWD9r2pkT908ATpij7mbg4NnTJUmSljqvECBJktQQL3yuZcUT2EqSWmfPmSRJUkMMZ5IkSQ0xnEmSJDXEcCZJktQQw5kkSVJDPFpTGsgjPSVJC8GeM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOc5kxaA50iTJA1lOJMatzPBzlAoSfc97taUJElqiOFMkiSpIYYzSZKkhhjOJEmSGuIBAZLm5MEEkrQ47DmTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaohHa0ra5bzklCTNn+FM0pIxbbADw52k9rhbU5IkqSH2nElSz12qklpgOJOkXcBxdpJ2FXdrSpIkNWTUcJbkmCQ3JrkpyclzzE+SP+nnX5Pk0KG1kiRJS9FouzWTrADOAJ4DbAIuT3JxVX16YrFjgYP62+HAW4HDB9ZK0rLn7lRp6RlzzNlhwE1VdTNAkguA44DJgHUccG5VFfCJJHsn2QdYPaBWkrRIFisUGka1HIwZzvYFbp14vImud2xHy+w7sFaSpAVhKNRCStdpNcKKkxcDz6uqE/rHLwUOq6pXTyzzt8AfVtU/9o8/CPwW8Kgd1U6sYx2wrn/4GODGbTRpJXD7PH+d5Va7mNu21trWahdz29ZaO0btYm7b2nt7ZFWtmj1xzJ6zTcD+E4/3AzYPXGaPAbUAVNVZwFk7akySDVW1ZsfNtnYxt22tta3VLua2rbV2jNrF3La1w4x5tOblwEFJDkyyB3A8cPGsZS4Gfqk/avOpwFeq6gsDayVJkpac0XrOqmprkpOAS4AVwNlVdV2SE/v5ZwLrgZ8EbgK+Afzy9mrHaqskSVIrRr1CQFWtpwtgk9POnLhfwKuG1u6kHe76tLaJbVtrbWu1i7lta60do3Yxt23tAKMdECBJkqTpefkmSZKkhhjOtiPJDye5IMk/J/l0kvVJfmSx27U9Sc5OcluSjfOo3S/Je5N8tv+d/29/QMaQ2v2T/H2S65Ncl+Q107d+ekkqyZsmHv9mkt9bgO3+QJJPJrm6/33/+5T1D+//vtckuTLJ25Lsv+PKxZPka7MevzzJ6QNr70ly1cRt9Rht3M72VyT5VJK/mbLud/v/7zV9u6c+32KSP01y5MBl53zPmc/rebEk+cMkRyX5mSzQpfeS3JLk2v5/tGHK2iuT7D7F8jPP5av72qfNo70z69iY5J1JHjBl/d5JLkxyQ/+ee8SU9V/b8VLfV/OYWa/hu5L82hT1r+1fSxuTnJ/kB6Ztw3wkeU2/zeuGtjfJqiT/2Nf9zMT09yZ5xMB17NwlKKvK2xw3IMDHgRMnph0C/PgU69gDuAzYbZ5t2BP4MLBiippnAIcCG+fx+34S+OX+8Qrg7cBpA+v3AQ7t7+8FfAZ4/AL8n/4d+Bywsn/8m8DvLdDz40H9/d2BfwKeOrD20cCngJ8D9uin/QSwAXj0wHWsBr4JXDXP59VVwN0zf7eBdV+b9fjlwOnzqV3oG/DrwHnA30xRc0T/HnD//vFK4BHz2PZVQ17D23vPmfb1vMh/6w/1z7E/Ao6cou4o4Jx5bvOWaZ7Ls2pPB46aYvmvTdx/HvDhOZbZ7v971jreAfz6lG3+c+CE/v4ewN5T1u/U67H/fPg3unN0DVl+3/59es/+8V8DL99Vz7ntbPeJwEbgAXRj7P8OOGhA3X8BfqX/LPtoP+0FwKlT/H3+me6crXsAVzPl5+Gy6DlL8kv9N9+rk/zFwLKjgW/XvQ9guKqqPjJ0u1V1N/BB4Oena/F3vQJ4d1XdM8U2LwPumMe2ngX8e1X9Wb+ee4DXAq8Y8q2uqr5QVVf2978KXE/3ghzbVroBl6+dT3GS1f03z//Xf7O6NMmeO6qrzsy3z93729ABnG8FXlZVf90/R6iqDwK/CLxpu5X39s9VdcgUy9Nv65t93ZznDlxqkuwH/BTwtilL9wFur6pvAVTV7VU11d8syeOAzwx8Dc/5nsO9r5YyZJsPTPK3/fvdxiSD33+S/Hpfs3GaXpG+9rQk1wA/RhcyTwDemuSUadazCN4HHDPP2gcDXwboewv/Psl5wLVTrOMjwH8YunCSB9N9CX87dJ8zVXXnFNvbFX6C7v3n81PU7AbsmWQ3urA0+LXUv0/fkOTP+8/yCwf2Nj4O+ERVfaOqttJ1drxwQN236b5g3B/4Tt/mXwNOG9jk716+sn+Pn7kE5WBLPpwleQLwu8CzqupgYOjuticCV+yCJrwHeMk8a18CvHcXtGGIJzDr962qu4B/YYo3DuheSMCT6XqThiz/kVnd5TO3Zw/c5BnAS5I8ZJp2TjgIOKOqngDcCfzHge1ekeQq4DbgA1W1w9833W7xLVV1TZLn97tFLkzyrqq6ge6NYOU8f4+x7Tn5/wFeP8/ai8Zq4Db8Md2VR74zZd2lwP5JPpPkLUmeOY9tHwu8f+Cyu+o95xhgc1UdXFVPHLr9JE+hO53R4cBTgV9J8uShG62q19EFsnPoAto1VfWkqprmeTJfBVya5Ip0V42Zxt/TBeOhZp7LN9AF/t+fmHcY8LtV9fghK+o/9I9lujD3KGAL8GfpdtW/LckDp6jfFY4HBl+Tqqr+FfjfdJ8nX6A7p+mlU27zMcBZVfUk4C7gPw+o2Qg8I8lD+zD3k9z7BPfbch5dr+j7gd/rt3VuVX1jYFu3dWnKwZZ8OKPrEbqwqm4HqKr59CrtjI10b1RTSTfW61FVdcsub9E2NsncPT/bmj73SpIHAe8Cfq0PdztUVT9eVYfMcfu7gfV3AefSdUXPx+f6HgroPhxXD9zuPX0P1H7AYUmeOKDsYOATSVYAp9I9P38DeG4//7PAgVO0fSF9c/L/A0zTIzJZO+Sb6y6R5PnAbVU1dejpe0afQnd5uC3AXyV5+ZSrmXmDX0jXAs9O8sYkP15VXxlY93Tgoqr6ev+7v5tul+o0nky3G/exwKeHFCT5pz7svw346YkQ/7wptntkVR1KF3ReleQZQwv7D9w7h44l4nvP5cfSBeFzk6Sf98mq+tyAdezZ/84b6ALL24e2l64H6lDgrVX1ZODrwIKM7YPvfjb9NPDOKWp+kK7n6EDgEcADk/zilJu+tao+2t//S7rn63ZV1fXAG4EP0L0Or6bb27Kjuq9U1U9Vd2b/K4HnA+/q97BcOGCMX+aYNtWpMZZDOJsqXEy4ju6Neaf0uzPuTrLXlKUr6XpxFsp1wL0uMdF3n+9Pt+98h9INqn0X8I6qevfQDe+CnjPoekdeCcznG+S3Ju7fw5Tn/+t3KfwDw3aNpN/GSrrdAnf2uwZmPsgeRtcTpwlJXjXxvBj6IQpwJN0H/i10uxaeleQvhxb3AfwfqupU4CQG9qr2bX4A3VigobtvdtV7zmf69VwL/OEUuxXn+kAZVpgc0oeNNwCvA/4WOKb/f213mEBVHd6H/ROAiydC/CVDtz/zN66q24CL6HqwpnEJ89i1WVUfp3stz1wb8esDSye/rLx6ZnjDQJuATRM99RfShbWFcixwZVV9cYqaZ9N9Cd5SVd+mC/7THkgx+3N80Od6Vb29qg6tqmfQDfn57JTbPYXueb2W7sv7K4A/2EHNkMtXbtdyCGcfBH4uyUMBkvzQwLoPAfdP8iszE5L82Dx3bdyfbuD6NL4JLMjRLL0PAg9I8kvQ7bKjG/90zpCu3P6b49uB66vq/0yz4Z3tOevXcQfdINNXTrPt+Up3NM/e/f096d58bhhQei3dQPPbgUcneUiSA4DHJflR4GFTjuNYFqrqjInnxeA3uar67arar6pW0+2K+VBVDfrGnu7otIMmJh0CTPO/OZpul9lQc77nAI+cYh304fUbVfWXdLuShn5wXwb8TJIH9LvJXkg3HmqHqhuPewj9gUB0v8vz+v/XN6dp/7TSjbHba+Y+XS/0tEe3zmvcWZLH0g3+/tK0tfNVVf8G3JrkMf2kn2BgL+UuspYpdmn2/gV4av/cCl2br59yHQdM9FitBf5xSFGSh/U/DwB+lina3r/+H1FVH6YbJ/cdulC4o8/mnb4E5ahXCGhBdZeMegPw4ST30B0l9/IBdZXkhcAfpzsM9t/pjgiadpDsQ+nGGH17ynZ/uR/T9ANVNTjYJTmf7qinlUk20R1dssMu84nf9y1J/htdcF8P/M7ATR8JvBS4tv8GDfA71V3pYaG8ia53YyHsA/x5H2LvB/x1Ve3wNA1VdX26MXkHA/+D7sP7ZroX7m/SfStTGx4EvLkP4VvpLjM3zXimY+l6NQbZVe85wI8CpyX5Dt3A5l8duP0rk5xDd9Q2wNuq6lNDN5pkFfDlqvpOksdW1UIFhocDF/V7FncDzquqqXYl96/LH0myonZ88MaeE+9xoTu4557v7dlcEK8G3tF/8N9Mf+nDsfW9wc8B/tM0dVX1T0kupNtFuJXuc3jaM+dfD7wsyZ/S9X69dWDdu/rP4W8Dr6qqL0+xzTfQjVmHLtS9h27c+nZ7o2sXXILSKwSMLMmLgCOq6jfmUft24PxpepDUvnRH8L0D+K90h3ZD17uxz5CA169jNd1pIYaMc9vWOm4B1syMx9SuleRK4PBpv5hpcSQ5E/iLiXFNasSueL+7r1kOuzUX2y8w/+tynQ68bBe2RQ3oB6n+NN34pSuBT9D1mF2+mO3SrtWPczGY3UdU1YkGM7Viye/WXEx9l/N7qurG+dRX1afSnTdnSFe77kOqahNw4k6s4h7gIUlmxvoM1o+R+zjdudmmPb2EJC2o6s5asGx6zcDdmpIkSU1xt6YkSVJDDGeSJEkNMZxJWjaS7J1ku5d9SXeNxEFHzUrSGAxnkpaTvRl2TT5JWjSGM0nLyf+kuzLDVUlO628bk1yb5OdnL9xfFeRTSR6V5ClJPpzu4tqXJNmnXwAoENwAAAFUSURBVOYf0l3H8pPpLpI+7fUoJeleDGeSlpOT6a5pegjd+eUOobtaw7Ppzqq/z8yCSZ4GnEl3weZbgTcDL6qqpwBn0509fMZuVXUY3dn8T12IX0TS0uV5ziQtV0+nuwLHPcAXk3wY+DHgLuBxdCePfm5VbU7yRLrzLH2gv0zPCuALE+t6d//zCmD1wjRf0lJlOJO0XG3vYohfoLu48ZOBzf2y11XVEdtY/lv9z3vwfVXSTnK3pqTl5KvAXv39y4CfT7Kiv2j3M/jeRb/vBH4K+IMkRwE3AquSHAGQZPckT1jQlktaNgxnkpaNqvoS8NEkG4EjgGuAq4EPAb9VVf82sewXgRcAZ9D1oL0IeGOSq4GrgKctcPMlLRNevkmSJKkh9pxJkiQ1xHAmSZLUEMOZJElSQwxnkiRJDTGcSZIkNcRwJkmS1BDDmSRJUkMMZ5IkSQ35/5i+GbP3XODNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot token distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "_ = sns.barplot(data=token_cnts.sort_values(\"cnt\", ascending=False), x=\"token\", y=\"cnt\", color=\"steelblue\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SMILESDataset(chembl[\"Smiles\"], vocabulary, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test producing batches with dataloader\n",
    "dataloader = tud.DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=dataset.getCollateFn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 23, 23,  ...,  0,  0,  0],\n",
       "        [ 1, 23, 23,  ...,  0,  0,  0],\n",
       "        [ 1, 29, 20,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 1, 23, 23,  ...,  0,  0,  0],\n",
       "        [ 1, 23, 29,  ...,  0,  0,  0],\n",
       "        [ 1, 23, 29,  ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(dloader_iter)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 103])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN modules\n",
    "\n",
    "The variational autoencoder consists of the following components:\n",
    "1. SMILES encoder: maps input sequences to a latent vector z\n",
    "2. Decoder: decodes a latent vector z into a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MolecularVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Encodes a sequence as a probability distribution over a latent space - z\n",
    "    and samples from this probability distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_sz:int, embedding_dim:int, hidden_dim:int, latent_dim:int, sos_idx:int, eos_idx:int, \n",
    "                 pad_idx:int, rnn_layers:int=1, bidirectional:bool=True, dropout:float=0.0):\n",
    "        \"\"\"Parameter initialization\"\"\"\n",
    "        super().__init__()\n",
    "        # module params\n",
    "        self.vocab_sz = vocab_sz\n",
    "        self.sos_idx = sos_idx\n",
    "        self.eos_idx = eos_idx\n",
    "        self.pad_idx = pad_idx\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.bidirectional = bidirectional\n",
    "        self.rnn_layers = rnn_layers\n",
    "        self.hidden_factor = (2 if self.bidirectional else 1) * self.rnn_layers\n",
    "        \n",
    "        # embedding layer (used by both encoder and decoder)\n",
    "        self.embedding = nn.Embedding(self.vocab_sz, self.embedding_dim, padding_idx=self.pad_idx)\n",
    "        \n",
    "        # encoder RNN\n",
    "        self.encoder_rnn = nn.GRU(self.embedding_dim, self.hidden_dim, num_layers=self.rnn_layers, \n",
    "                          batch_first=True, dropout=dropout, bidirectional=self.bidirectional)\n",
    "        \n",
    "        # linear layers for computing the params of the latent vector z posterior distribution\n",
    "        # (diagonal multivariate gaussian) from the hidden state vector of the RNN\n",
    "        self.hidden2mean = nn.Linear(self.hidden_dim * self.hidden_factor, self.latent_dim)\n",
    "        self.hidden2logv = nn.Linear(self.hidden_dim * self.hidden_factor, self.latent_dim)\n",
    "        \n",
    "        # linear layers for computing the decoder hidden vector from the latent vector\n",
    "        self.latent2hidden = nn.Linear(self.latent_dim, self.hidden_dim * self.hidden_factor)\n",
    "        \n",
    "        # decoder layers\n",
    "        self.decoder_rnn = nn.GRU(self.embedding_dim, self.hidden_dim, num_layers=self.rnn_layers, \n",
    "                  batch_first=True, dropout=dropout, bidirectional=self.bidirectional)\n",
    "        self.outputs2vocab = nn.Linear(self.hidden_dim * (2 if self.bidirectional else 1), self.vocab_sz)\n",
    "        \n",
    "    def forward(self, input_seqs:torch.Tensor) -> (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "        \"\"\"\n",
    "        Performs the encoding and reparametrization step.\n",
    "        ------------------------\n",
    "        input_seqs: input batch of sequences (batch size, seq. length)\n",
    "        \n",
    "        returns (z, mean, logv)\n",
    "        \"\"\"\n",
    "        input_embeddings = self.embedding(input_seqs)\n",
    "        # run sequence through the encoder\n",
    "        mean, logv, stdev = self.encode(input_embeddings)\n",
    "        # sample z from the posterior distribution\n",
    "        z = self.samplePosterior(mean, stdev)\n",
    "        # run through the decoder\n",
    "        logits = self.decode(z, input_embeddings)\n",
    "        return logits, z, mean, logv\n",
    "    \n",
    "    def encode(self, input_embeddings:torch.Tensor) -> (torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "        \"\"\"Encodes a sequence as parametrized posterior distribution over the latent space - z\"\"\"\n",
    "        _, hidden = self.encoder_rnn(input_embeddings)\n",
    "        # flatten RNN output\n",
    "        hidden = hidden.view(-1, self.hidden_factor * self.hidden_dim)\n",
    "        # reparametrize (compute posterior distribution params)\n",
    "        mean = self.hidden2mean(hidden)\n",
    "        logv = self.hidden2logv(hidden)\n",
    "        stdev = torch.exp(logv / 2)\n",
    "        return mean, logv, stdev\n",
    "        \n",
    "    def decode(self, z:torch.Tensor, input_embeddings:torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Decodes z as a distribution over the vocabulary for each position in the sequence\"\"\"\n",
    "        batch_sz = z.size(0)\n",
    "        hidden = self.latent2hidden(z)\n",
    "        hidden = hidden.view(self.hidden_factor, batch_sz, self.hidden_dim)\n",
    "        output, _ = self.decoder_rnn(input_embeddings, hidden)\n",
    "        return F.softmax(self.outputs2vocab(output), dim=-1)\n",
    "        \n",
    "    def samplePrior(self, batch_sz:int) -> torch.Tensor:\n",
    "        \"\"\"Samples z from a unit multivariate Gaussian\"\"\"\n",
    "        return torch.randn(batch_sz, self.latent_dim)\n",
    "\n",
    "    def samplePosterior(self, mean:torch.Tensor, stdev:torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the approximate multivariate Gaussian posterior parameterized by\n",
    "        mean vector and diagonal covariance matrix.\n",
    "        \"\"\"\n",
    "        batch_sz = mean.size(0)\n",
    "        epsilon = self.samplePrior(batch_sz)\n",
    "        return mean + stdev * epsilon\n",
    "    \n",
    "    def generateSequences(self, n:int=16, z=None, max_len:int=150, greedy:bool=False) -> torch.Tensor:\n",
    "        \"\"\"Generates a batch of sequences from latent space encodings.\"\"\"\n",
    "        # if z is not given, sample from prior\n",
    "        if not z:\n",
    "            z = self.samplePrior(n)\n",
    "        batch_sz = z.size(0)\n",
    "        sequences = torch.full([batch_sz, max_len], self.pad_idx, dtype=torch.long)\n",
    "        # set SOS idx at position 0 in the sequences\n",
    "        sequences[:, 0] = self.sos_idx\n",
    "        # running embeddings\n",
    "        input_embeddings = torch.zeros(batch_sz, max_len, self.embedding_dim)\n",
    "        # running sequences\n",
    "        running_mask = torch.ones(batch_sz).bool()\n",
    "        for s in range(1, max_len):\n",
    "            input_embeddings[running_mask, s-1, :] = self.embedding(sequences[running_mask, s-1])\n",
    "            logits = self.decode(z[running_mask, :], input_embeddings[running_mask, :s, :])\n",
    "            # sample from softmax at sequence position - s\n",
    "            next_idxs = self._sample(logits[: ,-1:, :], greedy=greedy).flatten()\n",
    "            sequences[running_mask, s] = next_idxs\n",
    "            # check for eos and pad signal and update running mask\n",
    "            running_mask = (sequences[:, s] != self.eos_idx) & (sequences[:, s] != self.pad_idx) \n",
    "            if running_mask.sum() == 0:\n",
    "                # all sequences are terminated\n",
    "                break\n",
    "        return sequences\n",
    "            \n",
    "    def _sample(self, logits:torch.Tensor, greedy:bool=False) -> torch.Tensor:\n",
    "        \"\"\"Samples idxs from a softmax distribution\"\"\"\n",
    "        if greedy:\n",
    "            # sample the most probable token at each sequence position\n",
    "            return logits.argmax(-1)\n",
    "        else:\n",
    "            # randomly sample from a softmax distribution at each sequence position\n",
    "            batch_sz, seq_len, vocab_sz = logits.size()\n",
    "            rand = torch.rand(batch_sz, seq_len, 1).repeat(1, 1, vocab_sz)\n",
    "            cdf = logits.cumsum(-1)\n",
    "            return (rand > cdf).long().sum(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = MolecularVAE(len(vocabulary), 8, 64, 128, vocabulary.getStartIdx(), vocabulary.getEndIdx(), \n",
    "                   vocabulary.getPadIdx(), rnn_layers=2, bidirectional=True, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, z, mean, logv = vae(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 103, 40])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples = vae.generateSequences(n=128, max_len=150, greedy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 37, 34, 18, 16, 25, 26, 19,  6, 30, 30, 35,  8, 39, 36, 35, 13, 25,\n",
       "        17, 27,  1, 39, 22, 17, 35, 38, 19, 20,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['%o+/))4C]#',\n",
       " 'o]86FH9)PPc-snc3F7I',\n",
       " '2@N#O/+\\\\Cl)H)',\n",
       " '7',\n",
       " '=',\n",
       " 'o9@o)Br2Pn8-=50s',\n",
       " 'o@0)8C\\\\5',\n",
       " 'N8',\n",
       " '92pC0',\n",
       " '5oP',\n",
       " 's@2n',\n",
       " 'I)H9%NosH0[Br1[4sSc',\n",
       " 'F',\n",
       " '2)F\\\\Br-',\n",
       " '0p',\n",
       " '[H1+F@(NCl=1Brn3O/C5/O\\\\5)1#Scs2-\\\\o-9P66])Pp8=BrC98[71[4F',\n",
       " 'IpN(n',\n",
       " 'N6-BrO2',\n",
       " 'c6',\n",
       " '2ClN8o',\n",
       " 'HC',\n",
       " '9[)3#F]-I',\n",
       " '',\n",
       " 'H%F/n2/+3Br+%P[6N2p0HClI==F/6N1FsHCl)ClCl\\\\c@]%P-%Hn-[@09%-N]09+HI4cBr0O7o7)c#0-5[n7=o5',\n",
       " 'Cl3+#]F9/+3@@/N4(6+\\\\S1',\n",
       " '',\n",
       " '%c2[@',\n",
       " '8/14@Br)@7ClS/Br]19F=]-nn%c(FsNSCl',\n",
       " '74p7',\n",
       " 'C0O4IN9S5[CN2Nc#17)\\\\O',\n",
       " 'Cl3@nBrOSCl#9]6P09Oc3HCl[[#nn][)cO%FFC(6(Cl=7',\n",
       " '3%=\\\\',\n",
       " '',\n",
       " 'C8PCl%S%8]%Br-+Cl]]\\\\)@FN=4Nc',\n",
       " '8=',\n",
       " 'Nsp(9Fs]-cp#ccBr))252',\n",
       " '9',\n",
       " '1c/=-()8/3@ClS2%Br\\\\Br',\n",
       " ']5o7',\n",
       " '@S%1IOS[FpS7',\n",
       " '+',\n",
       " 'BrO361',\n",
       " ']2]]HO)6[P3',\n",
       " '3#c@1)1',\n",
       " '9o#o844ClnFNn4[C#poBr8I3p-Fno@+%6OPS[PClP713P2/]F5o-35]24nBrCl8',\n",
       " '1nBr+N%)N96Br',\n",
       " '2-N\\\\3ClC=06#/N\\\\8',\n",
       " '1+11o\\\\8[s\\\\)6#C5BrC=n(8+[pp',\n",
       " 'IS9-@Br8IBr%#S2c()9',\n",
       " 'ISI0[F7C@',\n",
       " 'cCSSN]',\n",
       " '5+FC@3[2C)/4[3FFC297#2%7=/osSC7s18H=%2',\n",
       " '1%pNp(s50SF0(S#ICH[#/S3)C12',\n",
       " 'P(0O)',\n",
       " '(8Cl06I5Ic2)@ClN=8C3[9PFs',\n",
       " '%6\\\\]@Oc=@)N6@2F5',\n",
       " '',\n",
       " 'F',\n",
       " '(Cl(S%#o)pC+n[O+O',\n",
       " 'BrO',\n",
       " '#',\n",
       " 'N]',\n",
       " '#P+@FHn=%]2)@[]CCCC\\\\OSnn(=90nPpP)F120OnP\\\\c[',\n",
       " '',\n",
       " '\\\\Bro0\\\\p)%F[2F48C3O+-1n9/o7%%PS0C',\n",
       " '',\n",
       " '6]I6[NS+8nF2BrH]5',\n",
       " '#\\\\5',\n",
       " '[1)4o%8NOOF#9\\\\1O498]9@2%-+I@#1PBr[c)%50N-9o0/55)F',\n",
       " '',\n",
       " 'pn=F#9/4+(\\\\PH04+)1[N7)+1-8=[[#NP7S8PpF+PS\\\\Br)7=%+%2',\n",
       " '[I',\n",
       " '9N73C',\n",
       " '7PIn(@3]OBr(%-)4C1',\n",
       " '+oFCl3%[7FC25(',\n",
       " '0+',\n",
       " 'C\\\\n',\n",
       " '',\n",
       " '4',\n",
       " '5=Os7',\n",
       " '+ONClI\\\\n=',\n",
       " '',\n",
       " '1p%)5s6([2)Cl\\\\Ho',\n",
       " '#F8n%3@BrCS5@',\n",
       " 'CPC',\n",
       " '61p',\n",
       " '9]2#2(+)H',\n",
       " '8#@7O=[]+F50c73cP',\n",
       " '8Br7PCP',\n",
       " '',\n",
       " '2pCP=6H3=1C/+Br[/n29(P5Br\\\\On=p1C9%9c/SF@Cl+=N',\n",
       " '',\n",
       " '(n@#',\n",
       " '-c/P',\n",
       " '=/)spIClN/FO8p7S(ClN/POoC8-',\n",
       " 'cC2]ss37np]1+4F',\n",
       " 'N5P@C2@)',\n",
       " 'O]S/+]Brc]9p\\\\O9@+HS]O+ClCl#Cl/]]H/P',\n",
       " 'I+54/7+F%)=cI]F29pCCF#@n-0H@]\\\\)PN@CClp(PFpIo/o8Cl71oBrCl=9/9s12[)',\n",
       " ')N@nCl7PF6',\n",
       " '=',\n",
       " 'PSH=cSCl@4n1IHBrICCO#CBrF(7F/(%p/%(7@',\n",
       " '/7s22730N+@',\n",
       " 'n3)C',\n",
       " 'oPH-Br=9CSFBrBrH/+#/5C46FnBrn]3sBr9@S=6',\n",
       " '',\n",
       " 'N3#2opNC6]',\n",
       " '#5@',\n",
       " 'IBrO3%\\\\]4)/12)26S65Po8cn(/o-',\n",
       " 'N-9C4125BrClO@PBr+2n(-IP8#7+Br[1BrClS2-3)]o+P=20NcClN[Cl66',\n",
       " '/8+Br2+7%N(/[4Cl()pF[5/6]+@(+@2',\n",
       " '',\n",
       " '=@9Cl13ns5(8]Br2nNSBr)-#',\n",
       " '7-@0O[I1\\\\c4Sc[+20n',\n",
       " '(#[',\n",
       " '3#SSBr2BrO@6Cl[',\n",
       " '=',\n",
       " '',\n",
       " 'Br[-N[',\n",
       " '4',\n",
       " '6+Pn',\n",
       " '[367ClN550',\n",
       " ')(',\n",
       " '@[Cl',\n",
       " 'Cl3Oo\\\\-[OI',\n",
       " '#',\n",
       " '=',\n",
       " 'C=Nc3I##H1N]n41/)@17FcS214=[sON03/#']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_mols = [tokenizer.untokenize(vocabulary.decode(s)) for s in samples.tolist()]\n",
    "gen_mols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "code_folding": [
     0,
     16
    ]
   },
   "outputs": [],
   "source": [
    "def compute_loss(model:nn.Module, batch:torch.Tensor) -> tuple:\n",
    "    \"\"\"Computes the NLL and KL loss for a batch of sequences\"\"\"\n",
    "    batch_sz = batch.size(0)\n",
    "    # prepare targets (input shifted 1 step to the left and padded with pad idx)\n",
    "    targets = batch.roll(shifts=-1, dims=1)\n",
    "    targets[:, -1] = model.pad_idx\n",
    "    # prepare predictions\n",
    "    logits, _, mean, logv = model(batch)\n",
    "    preds = logits.permute(0, 2, 1)\n",
    "    # compute NLL (neg. log likleyhood) loss for the target sequence (ignore padding idx)\n",
    "    nll_loss = F.nll_loss(preds, targets, ignore_index=model.pad_idx, reduction=\"sum\") / batch_sz\n",
    "    # compute KL loss\n",
    "    kl_loss = -0.5 * torch.sum(1 + logv - mean.pow(2) - logv.exp()) / batch_sz\n",
    "    # compute total loss (averged within a batch)\n",
    "    return (nll_loss, kl_loss)\n",
    "\n",
    "def annealing_func(nll_loss, kl_loss, s:int, m:int, w:int):\n",
    "    kl_weight = 1 / (1 + np.exp((s - m)/w))\n",
    "    return nll_loss + kl_weight * kl_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(vae.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Batch: 0\n",
      "Batch: 1\n",
      "Batch: 2\n",
      "Batch: 3\n",
      "Batch: 4\n",
      "Batch: 5\n",
      "Batch: 6\n",
      "Batch: 7\n",
      "Batch: 8\n",
      "Batch: 9\n",
      "Batch: 10\n",
      "Batch: 11\n",
      "Batch: 12\n",
      "Batch: 13\n",
      "Batch: 14\n",
      "Batch: 15\n",
      "Batch: 16\n",
      "Batch: 17\n",
      "Batch: 18\n",
      "Batch: 19\n",
      "Batch: 20\n",
      "Batch: 21\n",
      "Batch: 22\n",
      "Batch: 23\n",
      "Batch: 24\n",
      "Batch: 25\n",
      "Batch: 26\n",
      "Batch: 27\n",
      "Batch: 28\n",
      "Batch: 29\n",
      "Batch: 30\n",
      "Batch: 31\n",
      "Batch: 32\n",
      "Batch: 33\n",
      "Batch: 34\n",
      "Batch: 35\n",
      "Batch: 36\n",
      "Batch: 37\n",
      "Batch: 38\n",
      "Batch: 39\n",
      "Batch: 40\n",
      "Batch: 41\n",
      "Batch: 42\n",
      "Batch: 43\n",
      "Batch: 44\n",
      "Batch: 45\n",
      "Batch: 46\n",
      "Batch: 47\n",
      "Batch: 48\n",
      "Batch: 49\n",
      "Batch: 50\n",
      "Batch: 51\n",
      "Batch: 52\n",
      "Batch: 53\n",
      "Batch: 54\n",
      "Batch: 55\n",
      "Batch: 56\n",
      "Batch: 57\n",
      "Batch: 58\n",
      "Batch: 59\n",
      "Batch: 60\n",
      "Batch: 61\n",
      "Batch: 62\n",
      "Batch: 63\n",
      "Batch: 64\n",
      "Batch: 65\n",
      "Batch: 66\n",
      "Batch: 67\n",
      "Batch: 68\n",
      "Batch: 69\n",
      "Batch: 70\n",
      "Batch: 71\n",
      "Batch: 72\n",
      "Batch: 73\n",
      "Batch: 74\n",
      "Batch: 75\n",
      "Batch: 76\n",
      "Batch: 77\n",
      "Batch: 78\n",
      "Batch: 79\n",
      "Batch: 80\n",
      "Batch: 81\n",
      "Batch: 82\n",
      "Batch: 83\n",
      "Batch: 84\n",
      "Batch: 85\n",
      "Batch: 86\n",
      "Batch: 87\n",
      "Batch: 88\n",
      "Batch: 89\n",
      "Batch: 90\n",
      "Batch: 91\n",
      "Batch: 92\n",
      "Batch: 93\n",
      "Batch: 94\n",
      "Batch: 95\n",
      "Batch: 96\n",
      "Batch: 97\n",
      "Batch: 98\n",
      "Batch: 99\n",
      "Batch: 100\n",
      "Epoch: 1\n",
      "Batch: 0\n",
      "Batch: 1\n",
      "Batch: 2\n",
      "Batch: 3\n",
      "Batch: 4\n",
      "Batch: 5\n",
      "Batch: 6\n",
      "Batch: 7\n",
      "Batch: 8\n",
      "Batch: 9\n",
      "Batch: 10\n",
      "Batch: 11\n",
      "Batch: 12\n",
      "Batch: 13\n",
      "Batch: 14\n",
      "Batch: 15\n",
      "Batch: 16\n",
      "Batch: 17\n",
      "Batch: 18\n",
      "Batch: 19\n",
      "Batch: 20\n",
      "Batch: 21\n",
      "Batch: 22\n",
      "Batch: 23\n",
      "Batch: 24\n",
      "Batch: 25\n",
      "Batch: 26\n",
      "Batch: 27\n",
      "Batch: 28\n",
      "Batch: 29\n",
      "Batch: 30\n",
      "Batch: 31\n",
      "Batch: 32\n",
      "Batch: 33\n",
      "Batch: 34\n",
      "Batch: 35\n",
      "Batch: 36\n",
      "Batch: 37\n",
      "Batch: 38\n",
      "Batch: 39\n",
      "Batch: 40\n",
      "Batch: 41\n",
      "Batch: 42\n",
      "Batch: 43\n",
      "Batch: 44\n",
      "Batch: 45\n",
      "Batch: 46\n",
      "Batch: 47\n",
      "Batch: 48\n",
      "Batch: 49\n",
      "Batch: 50\n",
      "Batch: 51\n",
      "Batch: 52\n",
      "Batch: 53\n",
      "Batch: 54\n",
      "Batch: 55\n",
      "Batch: 56\n",
      "Batch: 57\n",
      "Batch: 58\n",
      "Batch: 59\n",
      "Batch: 60\n",
      "Batch: 61\n",
      "Batch: 62\n",
      "Batch: 63\n",
      "Batch: 64\n",
      "Batch: 65\n",
      "Batch: 66\n",
      "Batch: 67\n",
      "Batch: 68\n",
      "Batch: 69\n",
      "Batch: 70\n",
      "Batch: 71\n",
      "Batch: 72\n",
      "Batch: 73\n",
      "Batch: 74\n",
      "Batch: 75\n",
      "Batch: 76\n",
      "Batch: 77\n",
      "Batch: 78\n",
      "Batch: 79\n",
      "Batch: 80\n",
      "Batch: 81\n",
      "Batch: 82\n",
      "Batch: 83\n",
      "Batch: 84\n",
      "Batch: 85\n",
      "Batch: 86\n",
      "Batch: 87\n",
      "Batch: 88\n",
      "Batch: 89\n",
      "Batch: 90\n",
      "Batch: 91\n",
      "Batch: 92\n",
      "Batch: 93\n",
      "Batch: 94\n",
      "Batch: 95\n",
      "Batch: 96\n",
      "Batch: 97\n",
      "Batch: 98\n",
      "Batch: 99\n",
      "Batch: 100\n"
     ]
    }
   ],
   "source": [
    "dataloader = tud.DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=dataset.getCollateFn())\n",
    "optimizer.zero_grad()\n",
    "for e in range(NUM_EPOCHS):\n",
    "    print(\"Epoch: %i\" %e)\n",
    "    for b, batch in enumerate(dataloader):\n",
    "        if b > 100:\n",
    "            break\n",
    "        print(\"Batch: %i\" % b)\n",
    "        optimizer.zero_grad()\n",
    "        # compute loss\n",
    "        nll_loss, kl_loss = compute_loss(vae, batch)\n",
    "        loss = nll_loss + kl_loss\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples2 = vae.generateSequences(n=32, max_len=150, greedy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC@cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n",
       " 'CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCH=ccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n",
       " 'cccccccccccc',\n",
       " '-cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n",
       " 'C7ccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n",
       " '1@CCCCCCCCCCCCCC=CCCCCCCCCCCCCCCCCCCCC/\\\\CCCCCPccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n",
       " 'CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC6ccccccccccccccccccccccCCC4ccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc)CCCCCCCCCCCCCCCCCC',\n",
       " ']0cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccCCCCCCCCCccccccccccccccccccccccccccc',\n",
       " 'ccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n",
       " 'ccccccccccccccccccccCCCCCCCCCCCCCcccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCNcccccccc',\n",
       " 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC8C1CCCCCCCCCCCCCccccccCCCCCCCCCCCCCCCCCCCCCCCCC',\n",
       " '(CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC',\n",
       " 'CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n",
       " 'ccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n",
       " 'CccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccCCCCCCCCCCCCCCCCCCCCCccccccccccc',\n",
       " 'IcccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccFcccc',\n",
       " 'CCCCCCCCCCCCCCCCCCCCCCCCC3ccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n",
       " 'CPCCCCCCCCCCCCCCCCCCCCCCCCCCCPCCCCCCCCCCCCCCCCCCCCCCCCCCCcccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n",
       " 'CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCcccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n",
       " '#CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC8CCCCCCCCCCCCCCCCCCCCNCCCCCC7ccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n",
       " 'CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC[CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCnCCCCCCCCCCcccccccccccc',\n",
       " '3cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccCCCCCCCCCCCCCCCCCCCCCCCCCCC',\n",
       " 'CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC1cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n",
       " 'Fcccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc#CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCcccccccccccccccccccccccccccccc',\n",
       " 'CCCCCCCCCCCCCCCCCCCCCCCCCCCCncccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccCCCCCpccccccccccc',\n",
       " 'PCCCCCCCCCCCCCCCCCC)CCCCCCCCCCCCCCCCCCCCCCCCCCpCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCcccccccccccccccccccccccccccccccccccccc',\n",
       " 'CCCCCccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC',\n",
       " '-8CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCNCC3ccccccccccccccc',\n",
       " 'CCOCCCCCCCCC2Clpccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc1ccccccccccccccccccccccccccccccccccccc',\n",
       " '',\n",
       " 'ccccccccoCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC[ccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc',\n",
       " '=oCCCCCCCC\\\\CCCCcccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_mols2 = [tokenizer.untokenize(vocabulary.decode(s)) for s in samples2.tolist()]\n",
    "gen_mols2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "385.875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
