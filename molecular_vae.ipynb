{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecular VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [11:56:04] Enabling RDKit 2019.09.1 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import torch.utils.data as tud\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# chemistry\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "IPythonConsole.ipython_useSVG=True  #set this to False if you want PNGs instead of SVGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChEMBL ID</th>\n",
       "      <th>Smiles</th>\n",
       "      <th>AlogP</th>\n",
       "      <th>QED Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL2333117</td>\n",
       "      <td>CC(C)Nc1c(C(N)=O)nnc2ccc(-c3cnn(C)c3)cc12</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL1189585</td>\n",
       "      <td>CC1C(=O)NC2=Nc3sc4c(c3CN21)CCCC4</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL4089494</td>\n",
       "      <td>CNC(=O)c1ccc(NC(=O)Nc2ccc(-c3nc(N4CCOCC4)c4ncc...</td>\n",
       "      <td>3.53</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL1189590</td>\n",
       "      <td>CN(C)c1nccc2c1nnn2Cc1ccccc1F</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL3927722</td>\n",
       "      <td>Cc1noc(C)c1Cn1cc(NC(=O)Cc2ccco2)cn1</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ChEMBL ID                                             Smiles  AlogP  \\\n",
       "0  CHEMBL2333117          CC(C)Nc1c(C(N)=O)nnc2ccc(-c3cnn(C)c3)cc12   1.95   \n",
       "1  CHEMBL1189585                   CC1C(=O)NC2=Nc3sc4c(c3CN21)CCCC4   1.95   \n",
       "2  CHEMBL4089494  CNC(=O)c1ccc(NC(=O)Nc2ccc(-c3nc(N4CCOCC4)c4ncc...   3.53   \n",
       "3  CHEMBL1189590                       CN(C)c1nccc2c1nnn2Cc1ccccc1F   2.08   \n",
       "4  CHEMBL3927722                Cc1noc(C)c1Cn1cc(NC(=O)Cc2ccco2)cn1   2.31   \n",
       "\n",
       "   QED Weighted  \n",
       "0          0.77  \n",
       "1          0.78  \n",
       "2          0.40  \n",
       "3          0.73  \n",
       "4          0.78  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chembl = pd.read_csv(\"data/cleaned_dataset.csv\")\n",
    "chembl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation & encoding\n",
    "\n",
    "Steps to prepare VAE input data:\n",
    "1. SMILES tokenization (add start/end tokens)\n",
    "2. SMILES token encoding (convert to integer indecies) -> build a vocabulary\n",
    "3. Set up a SMILES dataset class (for feeding batches of data to the VAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility classes/functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     53,
     133,
     170
    ]
   },
   "outputs": [],
   "source": [
    "class SMILESTokenizer(object):\n",
    "    \n",
    "    def __init__(self, pattern=\"(Br|Cl)\", start=\"<sos>\", end=\"<eos>\"):\n",
    "        self.pattern = re.compile(pattern)\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        \n",
    "    def getStart(self):\n",
    "        return self.start\n",
    "    \n",
    "    def getEnd(self):\n",
    "        return self.end\n",
    "    \n",
    "    def getPattern(self):\n",
    "        \"\"\"Returns compiled regex pattern for multi-character tokens\"\"\"\n",
    "        return self.pattern\n",
    "\n",
    "    def tokenize(self, smi:str, use_start_end:bool=True) -> list:\n",
    "        \"\"\"Tokenizes an input SMILES string\"\"\"\n",
    "        start = [self.start] if self.start else []\n",
    "        end = [self.end] if self.end else []\n",
    "        if not self.pattern:\n",
    "            if use_start_end:\n",
    "                return start + list(smi) + end\n",
    "            else:\n",
    "                return list(smi)\n",
    "        # split input SMILES string using the supplied regex pattern    \n",
    "        splitted = self.pattern.split(smi)\n",
    "        tokens = []\n",
    "        for i, s in enumerate(splitted):\n",
    "            # make sure Br and Cl are treated as a single token\n",
    "            if i % 2 == 0:\n",
    "                tokens.extend(list(s))\n",
    "            else:\n",
    "                tokens.append(s)\n",
    "        if use_start_end:\n",
    "            return start + tokens + end\n",
    "        else:\n",
    "            return tokens\n",
    "\n",
    "    def untokenize(self, tokens:list) -> str:\n",
    "        \"\"\"Concatenates a list of tokens into a SMILES string\"\"\"\n",
    "        smiles = \"\"\n",
    "        for t in tokens:\n",
    "            if self.start and t == self.start:\n",
    "                continue\n",
    "            if self.end and t == self.end:\n",
    "                continue\n",
    "            else:\n",
    "                smiles += t\n",
    "        return smiles\n",
    "    \n",
    "\n",
    "class SMILESVocabulary(object):\n",
    "    \"\"\"Keeps track of string tokens and their associated integer indecies\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._tokens_idxs = {} # vocabulary\n",
    "        self._current_idx = 0 # currently available index\n",
    "\n",
    "    def __getitem__(self, token_or_idx):\n",
    "        return self._tokens_idxs[token_or_idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._tokens_idxs) // 2\n",
    "    \n",
    "    def add(self, token:str):\n",
    "        assert type(token) == str, \"Token must be of type string.\"\n",
    "        if token not in self._tokens_idxs:\n",
    "            self._tokens_idxs[token] = self._current_idx\n",
    "            self._tokens_idxs[self._current_idx] = token\n",
    "            # update first available index\n",
    "            self._current_idx += 1\n",
    "            \n",
    "    def tokens(self):\n",
    "        \"\"\"Returns a list of all tokens in the vocabulary\"\"\"\n",
    "        return [t for t in self._tokens_idxs if type(t) == str]\n",
    "\n",
    "    def update(self, tokens:list):\n",
    "        \"\"\"Updates the vocabulary with an iterable of tokens\"\"\"\n",
    "        for t in tokens:\n",
    "            self.add(t)\n",
    "        \n",
    "    def encode(self, tokens:list) -> list:\n",
    "        \"\"\"Encodes a list of tokens as a list of integer indecies\"\"\"\n",
    "        return [self._tokens_idxs[t] for t in tokens]\n",
    "    \n",
    "    def decode(self, indecies:list) -> list:\n",
    "        \"\"\"Decodes a list of interger indecies as a list of tokens\"\"\"\n",
    "        return [self._tokens_idxs[t] for t in indecies]\n",
    "\n",
    "    def build(self, smiles:list, tokenizer:SMILESTokenizer) -> None:\n",
    "        \"\"\"\n",
    "        Builds a vocabulary using a list of SMILES and\n",
    "        an instance of a Tokenizer object. Any existing\n",
    "        vocabulary is reset.\n",
    "        -------------------------------\n",
    "        smiles - iterable of SMILES strings\n",
    "        tokenizer - instantiated SMILESTokenizer object\n",
    "        \n",
    "        returns None\n",
    "        \"\"\"\n",
    "        # reset current vocabulary\n",
    "        self.__init__()\n",
    "        # build new vocabulary\n",
    "        tokens = set()\n",
    "        for smi in smiles:\n",
    "            tokens.update(tokenizer.tokenize(smi, use_start_end=False))\n",
    "        # end-of-seq token gets idx 0 and start-of-seq token gets idx 1\n",
    "        self.update([tokenizer.getEnd(), tokenizer.getStart()] + sorted(tokens))\n",
    "        \n",
    "    def save(self, path):\n",
    "        \"\"\"Saves the vocabulary to disk\"\"\"\n",
    "        voc = [[k, v] for k, v in self._tokens_idxs.items() if isinstance(k, str)]\n",
    "        voc_df = pd.DataFrame(voc, columns=[\"token\", \"index\"])\n",
    "        voc_df.to_csv(path, index=False)\n",
    "    \n",
    "    def load(self, path):\n",
    "        \"\"\"Loads a stored vocabulary from disk\"\"\"\n",
    "        # reset current vocabulary\n",
    "        self.__init__()\n",
    "        # build vocabulary from csv file\n",
    "        voc_df = pd.read_csv(path)\n",
    "        for _, row in voc_df.iterrows():\n",
    "            token = row[\"token\"]\n",
    "            idx = row[\"index\"]\n",
    "            self._tokens_idxs[token] = idx\n",
    "            self._tokens_idxs[idx] = token\n",
    "            self._current_idx = max(self._current_idx, idx)\n",
    "        # update the currently available index\n",
    "        self._current_idx += 1\n",
    "\n",
    "\n",
    "class SMILESDataset(tud.Dataset):\n",
    "    \"\"\"Custom dataset class for producing batches of SMILES\"\"\"\n",
    "    \n",
    "    def __init__(self, smiles, vocabulary:SMILESVocabulary, tokenizer:SMILESTokenizer):\n",
    "        \"\"\"\n",
    "        Creates a dataset from an iterable of SMILES, a built vocabulary of tokens\n",
    "        and a SMILES tokenizer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self._smiles = list(smiles)\n",
    "        self._vocabulary = vocabulary\n",
    "        self._tokenizer = tokenizer\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns a molecule at index idx as an encoded SMILES tensor\"\"\"\n",
    "        smi = self._smiles[idx]\n",
    "        smi_enc = vocabulary.encode(tokenizer.tokenize(smi))\n",
    "        return torch.LongTensor(smi_enc)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._smiles)\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(enc_tensors):\n",
    "        \"\"\"\n",
    "        Pads encoded SMILES tensors to the same max. length using 0:s\n",
    "        The output tensor has shape: (batch_sz, max. length)\n",
    "        \"\"\"\n",
    "        batch_sz = len(enc_tensors)\n",
    "        max_len = max([t.size(0) for t in enc_tensors])\n",
    "        padded = torch.zeros((batch_sz, max_len), dtype=torch.long)\n",
    "        # pad encoded batch of SMILES\n",
    "        for i, t in enumerate(enc_tensors):\n",
    "            padded[i, :t.size(0)] = t\n",
    "        return padded\n",
    "\n",
    "\n",
    "def countTokens(smiles:list, tokenizer:SMILESTokenizer, tokenCol:str=\"token\", cntCol:str=\"cnt\") -> pd.DataFrame:\n",
    "    \"\"\"Computes the token frequency in the smiles iterable\"\"\"\n",
    "    token_cnts = {}\n",
    "    for smi in smiles:\n",
    "        # tokenize SMILES string\n",
    "        tokenized = tokenizer.tokenize(smi, use_start_end=False)\n",
    "        # count tokens\n",
    "        for t in tokenized:\n",
    "            try:\n",
    "                token_cnts[t] += 1\n",
    "            except KeyError:\n",
    "                token_cnts[t] = 1\n",
    "    return pd.DataFrame([[t, c] for t, c in token_cnts.items()], columns=[tokenCol, cntCol])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze token frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>12896279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(</td>\n",
       "      <td>7025189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>)</td>\n",
       "      <td>7025189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>2682981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c</td>\n",
       "      <td>18431345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>4604265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>=</td>\n",
       "      <td>2904352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>O</td>\n",
       "      <td>4388805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n</td>\n",
       "      <td>2124346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>3590237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>576826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>1781615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>s</td>\n",
       "      <td>190809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>530543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>F</td>\n",
       "      <td>577815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>o</td>\n",
       "      <td>190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cl</td>\n",
       "      <td>340814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[</td>\n",
       "      <td>1253085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@</td>\n",
       "      <td>1286887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>H</td>\n",
       "      <td>936158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>]</td>\n",
       "      <td>1253085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S</td>\n",
       "      <td>418728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>98750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>#</td>\n",
       "      <td>109078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Br</td>\n",
       "      <td>70038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>/</td>\n",
       "      <td>345947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\\</td>\n",
       "      <td>78135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6</td>\n",
       "      <td>11356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7</td>\n",
       "      <td>1131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>P</td>\n",
       "      <td>20234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>p</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>+</td>\n",
       "      <td>102796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>I</td>\n",
       "      <td>9080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>%</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token       cnt\n",
       "0      C  12896279\n",
       "1      (   7025189\n",
       "2      )   7025189\n",
       "3      N   2682981\n",
       "4      c  18431345\n",
       "5      1   4604265\n",
       "6      =   2904352\n",
       "7      O   4388805\n",
       "8      n   2124346\n",
       "9      2   3590237\n",
       "10     -    576826\n",
       "11     3   1781615\n",
       "12     s    190809\n",
       "13     4    530543\n",
       "14     F    577815\n",
       "15     o    190476\n",
       "16    Cl    340814\n",
       "17     [   1253085\n",
       "18     @   1286887\n",
       "19     H    936158\n",
       "20     ]   1253085\n",
       "21     S    418728\n",
       "22     5     98750\n",
       "23     #    109078\n",
       "24    Br     70038\n",
       "25     /    345947\n",
       "26     \\     78135\n",
       "27     6     11356\n",
       "28     8       516\n",
       "29     7      1131\n",
       "30     P     20234\n",
       "31     p        17\n",
       "32     +    102796\n",
       "33     I      9080\n",
       "34     9        17\n",
       "35     %         8\n",
       "36     0         4"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_cnts = countTokens(chembl[\"Smiles\"], tokenizer)\n",
    "token_cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot token distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "_ = sns.barplot(data=token_cnts.sort_values(\"cnt\", ascending=False), x=\"token\", y=\"cnt\", color=\"steelblue\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SMILESTokenizer()\n",
    "vocabulary = SMILESVocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary.build(chembl[\"Smiles\"], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save vocabulary\n",
    "# vocabulary.save(\"data/vocabulary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vocabulary\n",
    "vocabulary.load(\"data/vocabulary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SMILESDataset(chembl[\"Smiles\"], vocabulary, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test producing batches with dataloader\n",
    "dataloader = tud.DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=SMILESDataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 22, 34,  ...,  0,  0,  0],\n",
       "        [ 1, 27,  2,  ..., 35, 10,  0],\n",
       "        [ 1, 22, 28,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 1, 22, 27,  ...,  0,  0,  0],\n",
       "        [ 1, 22, 28,  ...,  0,  0,  0],\n",
       "        [ 1, 22, 34,  ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(dloader_iter)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 66])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN modules\n",
    "\n",
    "The variational autoencoder consists of the following components:\n",
    "1. SMILES encoder: maps input sequences to a latent vector z\n",
    "2. Decoder: decodes a latent vector z into a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MolecularVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Encodes a sequence as a probability distribution over a latent space - z\n",
    "    and samples from this probability distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_sz:int, embedding_dim:int, hidden_dim:int, latent_dim:int, sos_idx:int, \n",
    "                 rnn_layers:int=1, bidirectional:bool=True, pad_idx:int=0, dropout:float=0.0):\n",
    "        \"\"\"Parameter initialization\"\"\"\n",
    "        super().__init__()\n",
    "        # module params\n",
    "        self.vocab_sz = vocab_sz\n",
    "        self.sos_idx = sos_idx\n",
    "        self.pad_idx = pad_idx\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.bidirectional = bidirectional\n",
    "        self.rnn_layers = rnn_layers\n",
    "        self.hidden_factor = (2 if self.bidirectional else 1) * self.rnn_layers\n",
    "        \n",
    "        # embedding layer (used by both encoder and decoder)\n",
    "        self.embedding = nn.Embedding(self.vocab_sz, self.embedding_dim, padding_idx=self.pad_idx)\n",
    "        \n",
    "        # encoder RNN\n",
    "        self.encoder_rnn = nn.GRU(self.embedding_dim, self.hidden_dim, num_layers=self.rnn_layers, \n",
    "                          batch_first=True, dropout=dropout, bidirectional=self.bidirectional)\n",
    "        \n",
    "        # linear layers for computing the params of the latent vector z posterior distribution\n",
    "        # (diagonal multivariate gaussian) from the hidden state vector of the RNN\n",
    "        self.hidden2mean = nn.Linear(self.hidden_dim * self.hidden_factor, self.latent_dim)\n",
    "        self.hidden2logv = nn.Linear(self.hidden_dim * self.hidden_factor, self.latent_dim)\n",
    "        \n",
    "        # linear layers for computing the decoder hidden vector from the latent vector\n",
    "        self.latent2hidden = nn.Linear(self.latent_dim, self.hidden_dim * self.hidden_factor)\n",
    "        \n",
    "        # decoder layers\n",
    "        self.decoder_rnn = nn.GRU(self.embedding_dim, self.hidden_dim, num_layers=self.rnn_layers, \n",
    "                  batch_first=True, dropout=dropout, bidirectional=self.bidirectional)\n",
    "        self.outputs2vocab = nn.Linear(self.hidden_dim * (2 if self.bidirectional else 1), self.vocab_sz)\n",
    "        \n",
    "    def forward(self, input_seqs:torch.Tensor) -> (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "        \"\"\"\n",
    "        Performs the encoding and reparametrization step.\n",
    "        ------------------------\n",
    "        input_seqs: input batch of sequences (batch size, seq. length)\n",
    "        \n",
    "        returns (z, mean, logv)\n",
    "        \"\"\"\n",
    "        input_embeddings = self.embedding(input_seqs)\n",
    "        # run sequence through the encoder\n",
    "        mean, logv, stdev = self.encode(input_embeddings)\n",
    "        # sample z from the posterior distribution\n",
    "        z = self.samplePosterior(mean, stdev)\n",
    "        # run through the decoder\n",
    "        logits = self.decode(z, input_embeddings)\n",
    "        return logits, z, mean, logv\n",
    "    \n",
    "    def encode(self, input_embeddings:torch.Tensor) -> (torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "        \"\"\"Encodes a sequence as parametrized posterior distribution over the latent space - z\"\"\"\n",
    "        _, hidden = self.encoder_rnn(input_embeddings)\n",
    "        # flatten RNN output\n",
    "        hidden = hidden.view(-1, self.hidden_factor * self.hidden_dim)\n",
    "        # reparametrize (compute posterior distribution params)\n",
    "        mean = self.hidden2mean(hidden)\n",
    "        logv = self.hidden2logv(hidden)\n",
    "        stdev = torch.exp(logv / 2)\n",
    "        return mean, logv, stdev\n",
    "        \n",
    "    def decode(self, z:torch.Tensor, input_embeddings:torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Decodes z as a distribution over the vocabulary for each position in the sequence\"\"\"\n",
    "        batch_sz = z.size(0)\n",
    "        hidden = self.latent2hidden(z)\n",
    "        hidden = hidden.view(self.hidden_factor, batch_sz, self.hidden_dim)\n",
    "        output, _ = self.decoder_rnn(input_embeddings, hidden)\n",
    "        return F.softmax(self.outputs2vocab(output), dim=-1)\n",
    "        \n",
    "    def samplePrior(self, batch_sz:int) -> torch.Tensor:\n",
    "        \"\"\"Samples z from a unit multivariate Gaussian\"\"\"\n",
    "        return torch.randn(batch_sz, self.latent_dim)\n",
    "\n",
    "    def samplePosterior(self, mean:torch.Tensor, stdev:torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the approximate multivariate Gaussian posterior parameterized by\n",
    "        mean vector and diagonal covariance matrix.\n",
    "        \"\"\"\n",
    "        batch_sz = mean.size(0)\n",
    "        epsilon = self.samplePrior(batch_sz)\n",
    "        return mean + stdev * epsilon\n",
    "    \n",
    "    def generateSequences(self, n:int=16, z=None, max_len:int=150, greedy:bool=False) -> torch.Tensor:\n",
    "        \"\"\"Generates a batch of sequences from latent space encodings.\"\"\"\n",
    "        # if z is not given, sample from prior\n",
    "        if not z:\n",
    "            z = self.samplePrior(n)\n",
    "        batch_sz = z.size(0)\n",
    "        sequences = torch.full([batch_sz, max_len], self.pad_idx, dtype=torch.long)\n",
    "        # set SOS idx at position 0 in the sequences\n",
    "        sequences[:, 0] = self.sos_idx\n",
    "        # running embeddings\n",
    "        input_embeddings = torch.zeros(batch_sz, max_len, self.embedding_dim)\n",
    "        # running sequences\n",
    "        running_mask = torch.ones(batch_sz).bool()\n",
    "        for s in range(1, max_len):\n",
    "            input_embeddings[running_mask, s-1, :] = self.embedding(sequences[running_mask, s-1])\n",
    "            logits = self.decode(z[running_mask, :], input_embeddings[running_mask, :s, :])\n",
    "            # sample from softmax at sequence position - s\n",
    "            next_idxs = self._sample(logits[: ,-1:, :], greedy=greedy).flatten()\n",
    "            sequences[running_mask, s] = next_idxs\n",
    "            # check for eos signal and update running mask\n",
    "            running_mask = (sequences[:, s] != self.pad_idx) \n",
    "            if running_mask.sum() == 0:\n",
    "                # all sequences are terminated\n",
    "                break\n",
    "        return sequences\n",
    "            \n",
    "    def _sample(self, logits:torch.Tensor, greedy:bool=False) -> torch.Tensor:\n",
    "        \"\"\"Samples idxs from a softmax distribution\"\"\"\n",
    "        if greedy:\n",
    "            # sample the most probable token at each sequence position\n",
    "            return logits.argmax(-1)\n",
    "        else:\n",
    "            # randomly sample from a softmax distribution at each sequence position\n",
    "            batch_sz, seq_len, vocab_sz = logits.size()\n",
    "            rand = torch.rand(batch_sz, seq_len, 1).repeat(1, 1, vocab_sz)\n",
    "            cdf = logits.cumsum(-1)\n",
    "            return (rand > cdf).long().sum(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = MolecularVAE(len(vocabulary), 8, 64, 128, 1, rnn_layers=2, bidirectional=True, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, z, mean, logv = vae(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 66, 39])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples = vae.generateSequences(n=128, max_len=150, greedy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-=ScCl/6O4C[][C=7sSClpcoFc738s#=Br8p=]SF[FF[-#C(3cP8Br%Br%p[Br7%99]P%)#o4oOF/n=I9/7H',\n",
       " '2FH[O951p3S',\n",
       " 'cCN@cS+3so-',\n",
       " 'C[ClF22HSN[](S',\n",
       " '+(=2C81S',\n",
       " 'C5Ip[cOs]P(ocN#C[F968NBr2-s9H8Cl1pBrBrC+09F5',\n",
       " '2s7C34Br6Br]HC3S34n72+2II+1-s8Br',\n",
       " '+F1ClP\\\\93FpF-]@=/93%N@pOI8@1(353HsH=C)nSH99)c%=3=7]8+524ClcS1',\n",
       " '-Os6+)40(Cl4P/)S7]@@37=P+)nSBr4SBrBrBr5s=Br8c\\\\NS3\\\\I)FCl',\n",
       " '#1)cC7=7/BrS955P04PFFFClc/PS2)0s3p6O8c1n8',\n",
       " '/53NpCl%F#=BrBrS]cBrpSFH5NHCl7',\n",
       " '1n168[\\\\ss20S)#]35#\\\\#P@SP48@@@/5',\n",
       " '6=o3ScO9[523Br6\\\\+o[4)3Cl3I@o-]3#c%snCc[\\\\0o18-Pn9n6]Br]F6\\\\@cHOSBr228Fc(p=',\n",
       " '2H9+c)C[nonHS(6#2/%o#=/6P)3OIH#165F1#[+/\\\\7Br5C[4%3107=9NPnoO7NBr%Fp9oc3o466[@98ICoBr00s]1]4nF(=02%9##IF%',\n",
       " '1sF4on]2C]c[2=o%6Ip=n2=2+9\\\\+s(-(I59+)1+S+o31Cl(8(/S\\\\OP[nnsI[O#S%%Cc#/215NCc0(33FCl360P%n)]\\\\53]S]sBr\\\\[6841[(Is',\n",
       " 'S4Cs+',\n",
       " '+CNHo579/=S1Cl7sFp-cS(II[F3%1%53p3SO)7NC4S-5[\\\\61=spP-9@/(#S1]=2I7F@ClBr60-74[ClF/s@3',\n",
       " '[2Fo4%1)n0s)4o]F0',\n",
       " '2/n-+67SF5#)4([53OS5--oP]@n09nFp9[83\\\\)33+SF(n-P4pI8s]7Br@%=66355PC(+P1)H3)n/\\\\0O-I#8S45',\n",
       " '2C72O[s6\\\\]',\n",
       " 'C(4@BrN@4IBrc=np+)C124sBr+/5Fp+',\n",
       " '6o4]S6-o8%oO\\\\)SCS55S]s9cPIS%9I](=6c2OC)S833Cp5=@H)N6\\\\85#024=8',\n",
       " 'Cl%5=#/@-%s/F5C25nF1CI86]57H/Clppc6\\\\]O)//p]OI43o6I[3p81On1Ic/FNBr\\\\O-OC[#C',\n",
       " 'H50I42(\\\\ClN35HIoo5P-S\\\\](3FO]%F([PBrH]s\\\\nBr3=N++Clc[+30O(2Hc84Br3S/7S=3sCl8[18ooBr8FP=N5=+@C%2Br+)7O[c',\n",
       " 'H%%p9/Clnpp/4)%7\\\\H5C9C-/9(N9\\\\=)03onO+4o(s=N[N34[@c#-/H)\\\\-ClNc0\\\\4H4c\\\\H5@8nso@H[pFs27%Br07Br53]c)/72P2)%o1SHc5I184%o(7\\\\/s7ooC%)2I7n7%',\n",
       " '2214\\\\@%#7%',\n",
       " '@-(@0#1s7@C1p-C6CcSCCIS/%F4C57/=2-9In7O(c6C)3Cl@@#0Cls10o4oF/[C[@+82]p#-N7p@N0941+@-p',\n",
       " '%++\\\\S7/P+0',\n",
       " '',\n",
       " 'P+[(I3O9#8%5Br\\\\oo8)2%Cl',\n",
       " '0N23F=/4(2nC[C',\n",
       " '/%',\n",
       " '23C6460n7',\n",
       " '%\\\\O)S89N=(SC=[',\n",
       " '1\\\\/IF9ClO/Br',\n",
       " 'Cl79P68\\\\)',\n",
       " '81pI]/p\\\\o#4(3o=+P\\\\%#2P0403Cl6[7/@%H9=[#',\n",
       " 'F61c53@C9(I+%9P+I+5F5#oc]P69n@/#8]@BrF7',\n",
       " 'n6N6\\\\7-oClClH1#3)BrC[s[Brcs3oo@2\\\\%o5+=[/93F0Cl3',\n",
       " 'pNo+(3o7NIo%nNS6[22#5%/+S',\n",
       " '010C#/PHS55)SnC\\\\ss',\n",
       " '5%@93S\\\\+Br\\\\F]%2nH6Br)[8=n18N)I[-1',\n",
       " 'SIBr7s/]08n+Brc#4\\\\-CnI6',\n",
       " '(IIN/',\n",
       " '#(',\n",
       " '25N(PS%sHCCl\\\\=+SOFoSc20(P+7p%OP(/pBr]04%7np)p020SBrsC@]719P6F103O51\\\\1n29ns1cs+',\n",
       " 'o46s03/)\\\\/',\n",
       " '[+',\n",
       " '%o8)',\n",
       " '',\n",
       " 'Br%C0@0Po9Oc4Br0/Cl5+FC85+60nC\\\\1\\\\6%n[%-+5HCl#IH4C1S',\n",
       " ']P+PI-',\n",
       " '[S+]C#H/NC9sSc0=[#I5%C61=o9]2Br',\n",
       " '5)p9(C9',\n",
       " '0\\\\0P)cCs+P[9SF\\\\+]==5n@8PcpnN#()5(171Cl',\n",
       " '[4',\n",
       " '4p9n-Cl\\\\[[N#@SNn/784Cl4C',\n",
       " '4s\\\\=[N1+nCl##',\n",
       " '594n6oc)11\\\\84@p(SBr@N+%3%=P\\\\oBr@)1F-)9n',\n",
       " '@07o\\\\8=I\\\\SI2%%IOSpp)730/C65n-\\\\/1p742n2I35p0[ClS4S/0F7',\n",
       " '@7=Op#Br+-C4Cl/o',\n",
       " '4=Sc1+=-N%%\\\\ClNS=3',\n",
       " '',\n",
       " 'N#)6#34/ClP',\n",
       " '3I+Br(/#32O-0Br0cBr#\\\\FP',\n",
       " '5)I\\\\pC[pCC0]IH4[+)s1',\n",
       " '32c0-',\n",
       " '0nHp5[9[o8+I1OHc@(o',\n",
       " 'HI7I-Cl',\n",
       " 'HH)',\n",
       " 'o2\\\\O#BrF]OBr/nCl[/(Cl[/S=5sFs5/[]Fp3F//HC@-@=H9/N5Cl9+/HS3([-92\\\\-OC)H)28S',\n",
       " '5Cl\\\\37/IO+s%=FO+)%0',\n",
       " '7/os',\n",
       " '+5S-Sc-P+I(S6cP+oC7)',\n",
       " '3o(4O)H96O\\\\oo+IF38#%6)pCl4=9H[3H0F+9+2IN)@=9@S-n=p]F\\\\6%ClH5Ip8Cl%PF35P33[N6C+]%9Br7NH=60I(7(#',\n",
       " '',\n",
       " '/(s9pF#F53',\n",
       " '285n=ClBr/0BrnocC9(@928+5I/In%-2I9oC5P8=/c3[Snc7(\\\\/#Cl=p+',\n",
       " ')\\\\',\n",
       " 'BrC/@1',\n",
       " '7845+Br)n9P%=(2+O2PC2-(3(o@+HP6N@I\\\\',\n",
       " '4[O#%BrsO23spP/SF1s/%+ONBr=c=/=OH]',\n",
       " ')/2[%sP/Cl',\n",
       " 'oI4o6+1cs)]6N\\\\o=]@9OBrPCl6@7@8CInH+P',\n",
       " 'I#PNS)CPS2/Cl9BrO',\n",
       " '2O(0\\\\pF0([nS09N]3',\n",
       " '/1S=Cl2SFPsPN#FnO=982s294Fscc=Cl%s',\n",
       " 'Br=-5',\n",
       " 'Hp9cp47O#H7H\\\\-np6pn)7[-c@s\\\\5OP[IOClcCp',\n",
       " '=',\n",
       " 's]BrCl9/%/s++cs)sp=(cppsIF5',\n",
       " ')OI#F/6Cl4[\\\\H@]%9]',\n",
       " ']N3P(3p52\\\\-7',\n",
       " '6Cl#9/%4Br9s-5n=ClIc66S96H+NN]]%HpPn4Os',\n",
       " '(]4C#c5%H)5==ClI+CI#O1',\n",
       " 'ncnF#]\\\\=sCl(-6537Br-Cl5n98O@+(pn',\n",
       " '2\\\\34+HNCH7pFH2HP--8CClIIo#p1',\n",
       " 'C9S8H63N@9PPsn/330F',\n",
       " '+63)cSPIPH=s89',\n",
       " 'F4C(7#[\\\\Cl9/()ClO2C(F/',\n",
       " 'H0/(BrClH##H\\\\+Cl8p4[S\\\\9\\\\)/3H',\n",
       " 'Nc8F@3n=+-I(c9ClClO/7(p[4I0npBr9#+N',\n",
       " 'Bro+C/20[o40N@#8N9Clo92PN+8ClpSSp)p0[F6F00[9c[%sp8#0',\n",
       " 'c83-6c5cO%#0n87P4Brn-p8nHSH-NClnPnsN#-5-H[Cl[17N[O8\\\\F6Po)87pOCNIOc/3S\\\\84[]4[/S1I[Cl#',\n",
       " 'N#O+[553]7-Ic',\n",
       " 'H',\n",
       " '[(4+%=22+pNPH594/BrnO/11)17C945%Br\\\\56Cl',\n",
       " 'n#44+(S#CCl6[P=O(Fsop#5\\\\5c@s0P4c\\\\5cc(#%290[/6#/2[/C64I8c3%/FBrBr',\n",
       " '6PN2',\n",
       " '[7S3\\\\0F3S8#[+]P[2-0-1s407]NNcSoPN3p%749pO181PCl89@9Cl%+CP@',\n",
       " 'c3/6sF=0]O7s15O]P]',\n",
       " '#Br=',\n",
       " 'p%#9FBrpS7P76p=sp\\\\P/)P9(#7H\\\\1C89\\\\=4',\n",
       " '',\n",
       " '19',\n",
       " 'P-H=2',\n",
       " 'cH8/+P/[)Fp+Cns5I7-O89S/-5%18%71FI69P2I[[p#F623C0C',\n",
       " 'H#5I4F%p\\\\oS@#I15p%\\\\Ss)%#@Ip9IO(5#',\n",
       " 'FS3p%Br[]s+3Nc\\\\/F4@+%p\\\\4#P2s5IsF#)HI\\\\F2s(29[CClH]',\n",
       " '4no#\\\\8(+o0%C2)8-P\\\\-BroP6\\\\SF@pS5]2IOO=',\n",
       " 'C+-%CO0+C7-Cn1p=CIossc1-[@FI8',\n",
       " 'O-(CcS3)[n3s%@N+s#9C',\n",
       " '%89s)Hn)ClSS\\\\HF1+52]n/S8\\\\ClIsoC8oCl025HpBr+%',\n",
       " 'OFCl5C@n9]6F)30CPs75ClBr[5[Sn(nOH7]P',\n",
       " '50-Fn9]CIFH3',\n",
       " '5/)5BrH3084#/0',\n",
       " 'Br%S%%06)\\\\%=P[PONC#]P(o21/(+9opFsCl60',\n",
       " 'sn6BrI3(oFo6co@7N#N0%8N49ns3HcBr\\\\o2[Hs91\\\\#sFC@31\\\\9BrCN9)ClSP52CC2Br@0Cl\\\\HI%4%S95]+5p)\\\\#C5C4(S0%))OCln0c#8%O%S-C1)n8]#%#ClO1-Br=[=']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_mols = [tokenizer.untokenize(vocabulary.decode(s)) for s in samples.tolist()]\n",
    "gen_mols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute loss function\n",
    "\n",
    "**Note: will need to use a `<eos>` token so the model learns when to terminate a sequence!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model:nn.Module, batch:torch.Tensor) -> torch.Tensor:\n",
    "    # prepare targets (input shifted 1 step to the left and padded with pad idx)\n",
    "    targets = batch.roll(shifts=-1, dims=1)\n",
    "    targets[:, -1] = 0\n",
    "    # prepare predictions\n",
    "    logits, _, mean, logv = model(batch)\n",
    "    preds = logits.permute(0, 2, 1)\n",
    "    # compute NLL (neg. log likleyhood) loss for the target sequence (ignore padding idx)\n",
    "    nll_loss = F.nll_loss(preds, targets, ignore_index=0, reduction=\"sum\")\n",
    "    # compute KL loss\n",
    "    kl_loss = -0.5 * torch.sum(1 + logv - mean.pow(2) - logv.exp())\n",
    "    # compute total loss (averged within a batch)\n",
    "    loss = (nll_loss + kl_loss) / batch.size(0)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(vae.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Batch: 0\n",
      "Batch: 1\n",
      "Batch: 2\n",
      "Batch: 3\n",
      "Batch: 4\n",
      "Batch: 5\n",
      "Batch: 6\n",
      "Batch: 7\n",
      "Batch: 8\n",
      "Batch: 9\n",
      "Batch: 10\n",
      "Batch: 11\n",
      "Batch: 12\n",
      "Batch: 13\n",
      "Batch: 14\n",
      "Batch: 15\n",
      "Batch: 16\n",
      "Batch: 17\n",
      "Batch: 18\n",
      "Batch: 19\n",
      "Batch: 20\n",
      "Batch: 21\n",
      "Batch: 22\n",
      "Batch: 23\n",
      "Batch: 24\n",
      "Batch: 25\n",
      "Batch: 26\n",
      "Batch: 27\n",
      "Batch: 28\n",
      "Batch: 29\n",
      "Batch: 30\n",
      "Batch: 31\n",
      "Batch: 32\n",
      "Batch: 33\n",
      "Batch: 34\n",
      "Batch: 35\n",
      "Batch: 36\n",
      "Batch: 37\n",
      "Batch: 38\n",
      "Batch: 39\n",
      "Batch: 40\n",
      "Batch: 41\n",
      "Batch: 42\n",
      "Batch: 43\n",
      "Batch: 44\n",
      "Batch: 45\n",
      "Batch: 46\n",
      "Batch: 47\n",
      "Batch: 48\n",
      "Batch: 49\n",
      "Batch: 50\n",
      "Batch: 51\n",
      "Batch: 52\n",
      "Batch: 53\n",
      "Batch: 54\n",
      "Batch: 55\n",
      "Batch: 56\n",
      "Batch: 57\n",
      "Batch: 58\n",
      "Batch: 59\n",
      "Batch: 60\n",
      "Batch: 61\n",
      "Batch: 62\n",
      "Batch: 63\n",
      "Batch: 64\n",
      "Batch: 65\n",
      "Batch: 66\n",
      "Batch: 67\n",
      "Batch: 68\n",
      "Batch: 69\n",
      "Batch: 70\n",
      "Batch: 71\n",
      "Batch: 72\n",
      "Batch: 73\n",
      "Batch: 74\n",
      "Batch: 75\n",
      "Batch: 76\n",
      "Batch: 77\n",
      "Batch: 78\n",
      "Batch: 79\n",
      "Batch: 80\n",
      "Batch: 81\n",
      "Batch: 82\n",
      "Batch: 83\n",
      "Batch: 84\n",
      "Batch: 85\n",
      "Batch: 86\n",
      "Batch: 87\n",
      "Batch: 88\n",
      "Batch: 89\n",
      "Batch: 90\n",
      "Batch: 91\n",
      "Batch: 92\n",
      "Batch: 93\n",
      "Batch: 94\n",
      "Batch: 95\n",
      "Batch: 96\n",
      "Batch: 97\n",
      "Batch: 98\n",
      "Batch: 99\n",
      "Batch: 100\n",
      "Batch: 101\n",
      "Batch: 102\n",
      "Batch: 103\n",
      "Batch: 104\n",
      "Batch: 105\n",
      "Batch: 106\n",
      "Batch: 107\n",
      "Batch: 108\n",
      "Batch: 109\n",
      "Batch: 110\n",
      "Batch: 111\n",
      "Batch: 112\n",
      "Batch: 113\n",
      "Batch: 114\n",
      "Batch: 115\n",
      "Batch: 116\n",
      "Batch: 117\n",
      "Batch: 118\n",
      "Batch: 119\n",
      "Batch: 120\n",
      "Batch: 121\n",
      "Batch: 122\n",
      "Batch: 123\n",
      "Batch: 124\n",
      "Batch: 125\n",
      "Batch: 126\n",
      "Batch: 127\n",
      "Batch: 128\n",
      "Batch: 129\n",
      "Batch: 130\n",
      "Batch: 131\n",
      "Batch: 132\n",
      "Batch: 133\n",
      "Batch: 134\n",
      "Batch: 135\n",
      "Batch: 136\n",
      "Batch: 137\n",
      "Batch: 138\n",
      "Batch: 139\n",
      "Batch: 140\n",
      "Batch: 141\n",
      "Batch: 142\n",
      "Batch: 143\n",
      "Batch: 144\n",
      "Batch: 145\n",
      "Batch: 146\n",
      "Batch: 147\n",
      "Batch: 148\n",
      "Batch: 149\n",
      "Batch: 150\n",
      "Batch: 151\n",
      "Batch: 152\n",
      "Batch: 153\n",
      "Batch: 154\n",
      "Batch: 155\n",
      "Batch: 156\n",
      "Batch: 157\n",
      "Batch: 158\n",
      "Batch: 159\n",
      "Batch: 160\n",
      "Batch: 161\n",
      "Batch: 162\n",
      "Batch: 163\n",
      "Batch: 164\n",
      "Batch: 165\n",
      "Batch: 166\n",
      "Batch: 167\n",
      "Batch: 168\n",
      "Batch: 169\n",
      "Batch: 170\n",
      "Batch: 171\n",
      "Batch: 172\n",
      "Batch: 173\n",
      "Batch: 174\n",
      "Batch: 175\n",
      "Batch: 176\n",
      "Batch: 177\n",
      "Batch: 178\n",
      "Batch: 179\n",
      "Batch: 180\n",
      "Batch: 181\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-9c1ac148e0d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m# update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reinvent_shared.v2.1/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reinvent_shared.v2.1/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataloader = tud.DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=SMILESDataset.collate_fn)\n",
    "optimizer.zero_grad()\n",
    "for e in range(NUM_EPOCHS):\n",
    "    print(\"Epoch: %i\" %e)\n",
    "    for b, batch in enumerate(dataloader):\n",
    "        if b > 100:\n",
    "            break\n",
    "        print(\"Batch: %i\" % b)\n",
    "        optimizer.zero_grad()\n",
    "        # compute loss\n",
    "        loss = compute_loss(vae, batch)\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples2 = vae.generateSequences(n=32, max_len=150, greedy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cl==Cl[==Cl=ClCl=N2=ClCl==Cl====N212=N2======N2222===Cl====ClClCl=Cl2===2==N222n2212=N2=ClCl=C2==Cl=2==222=N2Cl===N2==N2n2222=Cl22==N22===Cl=N2=Cl==ClCl===ClN2=nnnnnnnnnnnn',\n",
       " 'CClClClClClClClClClClNCl=ClClC2ClClClClClClClClCl=ClN2ClClN2ClClNClN2ClClClClClCN2NClClClClClClClClCClClClN2ClClClClClClClClClClCN2ClClN2N2ClClClClClClClClClNCClClClClNClNClClN2ClClClClClClClCClClClClClClClClClN2ClClClClClClClClClClClClCl)cnnnnncnnnn',\n",
       " 'c1cc4cccc1cc1cccc1c4cc1cccc1cccccncccccccccccccccc4ccccccccccccc1cccc1cc4ccc1cc4cc1cccccc4ccc4cccccccc14ccc4ccccc4c1c4c1c1cc4cccccccc44ccnnnnnnnnnnnn',\n",
       " '=)nnnnnnnnnnnnnnnnnnnnnnn1nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn4nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn2=)=))=)n)2',\n",
       " ')ncc4c14nnnnnnn4nnn4)nnnnnn4nnnc4c44nn)nn4)nn4)nn4)n44ncnnnnnnc44nnnnc4n)n4nnnnnn4nnn4nc4)nn4nn4nc4nnnnnncnnnn4nnn4)nn44c4nn4nn4)444ncn4cnnnncnnnnnnc',\n",
       " 'nnncnnnnnn)nnnnnnnnnnnnnn)nnnnnnnnnnnn4nnnnnnnncnnnnnnnnnnnnnnnnnnnnnnncnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnncnncnnnnnnncnnnn4n1nnnnn2n',\n",
       " '))Cl)n)22)n1nn2))N2n2))nn4nnn22)nnnnnn2)nnn2))NnnCl))n1N)nCl)2n2)nnn22)2Cl)4)n2Cl)nn)Cl)nnnnn2)n2)nn22Cl)))1nn222)n2nn22)nnn222)))n)nnn2)n2)n2)',\n",
       " 'N1)nncnnnncnnnnnnnnnnnnncnnnnnnnnnnnnnncncnnnnncnnnnnn4)n1nnncnnnnnnncnnnnnnnnnnnnnnnnnnnnnnnnncnnnnnnnnnnnnnnnnnnnnnnn4)nncnn)nnnn)nnnncHClCCCCCCCCCN',\n",
       " '@14nnnnnn2nnn4nnn44nn4nnn4nnnnnnnn1nn14nnnn4nnnnnnn)n2nn1n)nnnnnnnnn1n)n1nnnn1nnnnnnnn1n1nnnnnnnnnnnn4nnnnnn4nnnnnnnnnnnnnnnnnnnnnn2nnnnnnnnnnnnnnnn2',\n",
       " 'CCCCCCNCCCCCCCNCCCNCCCNCCCCCNCCNCCCCCNCNNCCCCCCCNCCCCCNCCCCCNCCCCNCCCNCCNCNCCCNCCNCCCCCNCCNCCCCNCNCCCCCNCCCCNCNCNCCCCCCCCNCCCCCCNCNCCCCCN4nnnnnnnnnnn',\n",
       " 'NNNnnnnnnnnnnNnnnnnnnnNnnnnnn2nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnNnNNnnNNnnnnnnnnnnnnnnNnnnnnnnnnnnnnnnnnnnnnnnnnnNNNNnnnnnnnccccccccccc4',\n",
       " 'nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn)nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn2n222=N2n221',\n",
       " 'ccccccccccccc4ccccccccccccccccc4ccccccccc4cccccnccccccccccccc4cccccccccccccccccccccccccccccccccccc4cccccc4cccccccccccccccccccccccccccccccccc4cccccccc',\n",
       " 'ClCl==N=Cl==N22==ClCl=Cl2===N2=Cl=N2nn222n222=Clnn2n22=ClCl=Cl=Cl=N=Cl=Cln22=Cln22=N2=Cl==N22=222==ClCl==ClCl==ClNN22=ClCl2n222222==ClCl=N222=N2=Cl=Cl==Cl=Cl=N2=ClCl=N2CCClClCClCCCClClCl',\n",
       " 'ccccc)4cn4cccccc4nccnc4cccc4)c4cnc4cccccncccccncc4nccnc4)ccccccccccc4ccccnc4ccccc4ncccccnccncncccnc4nccccnccccncccccccnccccccncc4cccccccc2CCCCCClCCCCC',\n",
       " 'CCCClCCCCCCCCCCCCCCCCC2CCCCC2CCCCCCCCCCCCCCCCCCCCCCCCClCCCCCCClCCCC2CCCCCCCC22CCC2ClCCCCCCCC2CCCCCC2CCCCCCCCClCCCCCCCCCCCCCCCCCCCCCCCCNClCCCCCCClClClClClClClClCClClCl',\n",
       " 'CCCCCCCCC2CCCCCCCCCC2CCCC2CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC2CCCCCCCCCCCCCC2CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC',\n",
       " 'ClClClClClClClClClClClClClClClClClClClClClClClClClClClClClClClClClClClClClClClClClClClClClClClCClClClClClClClClClClCl==ClClClClCClClClClClClClClClClClClClClClClClClClClClCClClClClClClClClClClClClClClClClClClClClClClClClClCClClClClClClClClClClClClClClClClClClClClClClCl11c1cc4c1c14',\n",
       " 'CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCClCCCCCCCCCCCCCCCCCCCCCCCHCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCClCCCCHCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC1(21(21(((((',\n",
       " 'c4cc44c1c1c1c1c1c1cc1c1c4ccc1cc1c1ccc1c1ccc1c1ccccc1c1cc1c1c1c41c4c1cccc1ccccc14c1c4cccc14c4c1c1c1c1cc1cc1cc1cc4cccc1c44c1cc1cc4c1c4cccc1Cln2n2n2nn2n2',\n",
       " '((1(((((((((((2(((((((((1((((c1((((((p((((([(((((((((((((Br((Cl((+(((((n((((#((((((((((((N(((((((c11((Cl(1((((((\\\\(((1(((((((+((((((51(N((((((nn1nnnnnnnn',\n",
       " 'NNNn2ClNClNNn2N2n2N2NClNClNClN2N(N2=NNNN=N22n22N2N2N2N2NN2NN2N2N2N2ClNN2n2N2=ClClNNNClNN2ClNN2NClClN2ClN2N2NN22N2n222N2=N2=NNN2N2N2ClN=N=N2NN2nn2N2ClClN2c4ccccc4c1cc',\n",
       " 'Nnnnnnnnnnn)n2nnnnnnnnnnnnnnnnnn)nnnnnnnnnnn2nnnnnnnn)n4nnn2nnnnnnnnnnnnnnnnnn22nnnnnnnnnnn2nnnnnnnnnnnnnnnnnnnnnnn4n)nnnnnnnn2nnnnnnnnnn)n)Nn)Nn)nnn',\n",
       " 'cc1cc4c1cc1cccccc44ccccc4cc1c1cccc4ccc1ccccc4ccc4c1cccccccccc4c4ccc1cc1c1cccc4cc4c1cccccc4cccccccccc4cccccccc1cccccccc4c2ccccc4cc1cc1ccccnNNNNNNNNNNN',\n",
       " 'NN)Nnnn)nnnnnn)nNNnnnn)nnnnn)nnnnn)nNnnnnnnnn)nnn)n)n)Nn)Nnn)Nnn)n)nnnn)nnnn)nnn)nnnnnnnn)Nnn)nnnn)Nnn)nnnnn)nnnn)nnnnnn)Nnnnnn)Nnn)nnnnn222222222222',\n",
       " 'NNNNNNNNNNNNNN=NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNClNN2NNNNNNNNNNNNNNNNNNNNNNNNNNNClNNNNNNNNNNNNNNNNNNNNNClNNNNNNNNNNNClNNNClNNNNNNN)nn14N1c1c12',\n",
       " '2222222222222222222222222222222222222222222222222222222222222222222222222Cl2222222222222222222222222222222222222222222222222222222222222221cn4)nncn)nn',\n",
       " ')n1)=Nn4)c222c122)1)n22)221n)))2)N2)222nc2n21)n)22)n2)n))N2)))n221))n4)))n))n22)222)1)2)))N24nc2)2)nnn22))N222)N2222)21c2n221N122)1ncc2))2222n222n222',\n",
       " 'n)ncnncccnnnncnn4cnncc2cc4)n)nc4cc2c14)ncnnncncccncnn)nnccnccn4)nn4ccnccccccnnccnnnnnnnccnnnncn4cnnnc4ncn)nncccnnn))ncc2)4)nn)ccnnccnnnnc4))N)Nnn))nn',\n",
       " '==N2n222222n2222nn222n222nnn22224n22n22n2n22222n222=N222n22n2nn2222n2n222=N2222=ClN2n2n222n2222n22n22n2222222===222N22nn22n222n2=N2222n222)NNNNNNNNNNN',\n",
       " ')N))nn4)nn)n)n)n)n)n)ncn4n)nnn)Nnn)n)nn)nnnnn))n)ncn))n)nn))n)n)nn))nnnnn)nn))nnnnnn)n))Nnnnn)ncnnn))n))nnnncn)nnn))nn)nnn)n)Nn)ncnnnnn)N22HC2C22C2C2',\n",
       " 'NNNNNNN2NNNN2)NN)N2N2=NN=NN2)N2NNN2NNN=N2NN2NNNN2NCl)N2N2N=NN23)NN2)N2ClNNNN=N2N2N=N=NN2)NNn)NNNNN2N2NN2)NN2N=N2N22NN2=NNNNNN2)N2N2=NNN2=NN111c1111141c']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_mols2 = [tokenizer.untokenize(vocabulary.decode(s)) for s in samples2.tolist()]\n",
    "gen_mols2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "385.875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
