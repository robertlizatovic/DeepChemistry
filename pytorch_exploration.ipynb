{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.3845, 0.8900],\n",
      "        [0.2554, 0.9199]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.2354, 0.9639, 0.1382],\n",
      "        [0.5726, 0.1465, 0.3805]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.eig(\n",
       "eigenvalues=tensor([[4.3318, 0.0000],\n",
       "        [0.4857, 0.0000],\n",
       "        [0.2914, 0.0000]]),\n",
       "eigenvectors=tensor([[-0.6660, -0.6922, -0.2781],\n",
       "        [-0.5465,  0.7065, -0.4497],\n",
       "        [-0.5077,  0.1475,  0.8488]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear algebta functions\n",
    "torch.eig(tensor.matmul(tensor.T), eigenvectors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy tensors\n",
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output tensor\n",
    "q = 3*a**2 + b\n",
    "r = q * a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([36., 93.], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute gradients\n",
    "r.backward(gradient=torch.ones_like(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12., 18.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<PowBackward0 at 0x7f5f963d7828>, 0), (None, 0))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# traverse the DAG\n",
    "q.grad_fn.next_functions[0][0].next_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ConvNet\n",
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # conv layers\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # fc layers\n",
    "        self.fc1 = nn.Linear(16*6*6, 120)\n",
    "        self.fc2 = nn.Linear(120, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # apply convolutions and downsampling\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # flatten input tensor\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "        \n",
    "    def num_flat_features(self, x):\n",
    "        shape = x.size()[1:] # don't count the batch dimension\n",
    "        n_feat = 1\n",
    "        for d in shape:\n",
    "            n_feat *= d\n",
    "        return n_feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cn = ConvNet()\n",
    "print(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 3, 3])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 3, 3])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 576])\n",
      "torch.Size([120])\n",
      "torch.Size([64, 120])\n",
      "torch.Size([64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# learnable params\n",
    "for p in cn.parameters():\n",
    "    print(p.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0160,  0.0211,  0.0481,  0.0145,  0.0476, -0.0901,  0.1012,  0.0534,\n",
      "          0.1393, -0.0195],\n",
      "        [-0.0133,  0.0203,  0.0451, -0.0230,  0.0440, -0.1155,  0.1108,  0.0148,\n",
      "          0.1849, -0.0382],\n",
      "        [-0.0049,  0.0212,  0.0854, -0.0192,  0.0530, -0.1178,  0.0923,  0.0362,\n",
      "          0.1653, -0.0411],\n",
      "        [-0.0149, -0.0164,  0.0443, -0.0172,  0.0585, -0.0874,  0.0731,  0.0426,\n",
      "          0.1373, -0.0412]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# random input batch\n",
    "data = torch.randn(4, 1, 32, 32)\n",
    "y = cn(data)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backprop\n",
    "cn.zero_grad()\n",
    "y.backward(gradient=torch.randn(4, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect computed parameter gradients\n",
    "cn_params = list(cn.parameters())\n",
    "len(cn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0100, -0.0890,  0.0338,  0.0380, -0.0360, -0.3052, -0.1569,  0.0819,\n",
       "        -0.2681, -0.0612,  0.0151, -0.0623, -0.1875, -0.0663,  0.0347, -0.1055])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_params[3].grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy input and targets\n",
    "data = torch.randn(4, 1, 32, 32)\n",
    "pred = cn(data)\n",
    "target = torch.randn_like(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7002,  1.4774,  0.3304, -0.2408, -0.6467, -1.4701,  0.5988, -0.8106,\n",
       "         -0.8798,  0.1577],\n",
       "        [ 0.5366,  0.9574, -0.0164, -0.5578,  0.1467, -0.2498, -1.2092,  1.2324,\n",
       "          0.6097, -1.1467],\n",
       "        [-0.4037,  0.3217, -1.3192,  1.9048, -0.5673, -1.0156,  0.7784, -2.4793,\n",
       "         -0.7999, -0.2350],\n",
       "        [ 1.4927, -0.3113,  1.0824,  0.1498,  1.4842, -0.3042, -0.2295, -0.3804,\n",
       "          2.1648,  0.6430]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9649, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss function\n",
    "mse = nn.MSELoss()\n",
    "loss = mse(pred, target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0034, -0.0019, -0.0026, -0.0022, -0.0062, -0.0106])\n"
     ]
    }
   ],
   "source": [
    "# compute gradients\n",
    "cn.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(cn.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(cn.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect computed parameter gradients\n",
    "cn_params = list(cn.parameters())\n",
    "len(cn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.2930, -0.1676,  0.2038],\n",
       "          [ 0.0782,  0.1913, -0.1186],\n",
       "          [-0.2752,  0.1125,  0.0702]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0406,  0.0976,  0.2261],\n",
       "          [ 0.1427, -0.0462, -0.2141],\n",
       "          [-0.0154, -0.3233,  0.1652]]],\n",
       "\n",
       "\n",
       "        [[[-0.1747,  0.0425, -0.1593],\n",
       "          [ 0.1950,  0.0265, -0.1779],\n",
       "          [ 0.0491,  0.1404, -0.1922]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0414, -0.1219, -0.1255],\n",
       "          [ 0.0629, -0.3287, -0.2671],\n",
       "          [ 0.2675,  0.2972, -0.2151]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0926,  0.3157, -0.1293],\n",
       "          [-0.0129,  0.1018,  0.1835],\n",
       "          [-0.0410, -0.3076,  0.3066]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1276,  0.3241,  0.0871],\n",
       "          [ 0.0999, -0.0062,  0.0729],\n",
       "          [ 0.0083, -0.1388, -0.0614]]]], requires_grad=True)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optim.SGD(cn.parameters(), lr=0.01)\n",
    "\n",
    "# update weights\n",
    "cn.zero_grad()\n",
    "pred = cn(data)\n",
    "loss = mse(pred, target)\n",
    "loss.backward()\n",
    "sgd.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.2930, -0.1676,  0.2038],\n",
       "          [ 0.0782,  0.1913, -0.1186],\n",
       "          [-0.2752,  0.1125,  0.0702]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0406,  0.0976,  0.2261],\n",
       "          [ 0.1427, -0.0462, -0.2141],\n",
       "          [-0.0154, -0.3233,  0.1652]]],\n",
       "\n",
       "\n",
       "        [[[-0.1747,  0.0425, -0.1593],\n",
       "          [ 0.1950,  0.0265, -0.1779],\n",
       "          [ 0.0491,  0.1404, -0.1922]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0414, -0.1219, -0.1255],\n",
       "          [ 0.0629, -0.3287, -0.2671],\n",
       "          [ 0.2675,  0.2972, -0.2151]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0926,  0.3157, -0.1293],\n",
       "          [-0.0129,  0.1018,  0.1835],\n",
       "          [-0.0410, -0.3076,  0.3066]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1276,  0.3241,  0.0871],\n",
       "          [ 0.0999, -0.0062,  0.0729],\n",
       "          [ 0.0083, -0.1388, -0.0614]]]], requires_grad=True)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "363.875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
